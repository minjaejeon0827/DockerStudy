[코딩애플] 도커 Docker & Container 내용 요약

도커 Docker 다운로드 방법
참고 URL - https://junesker.tistory.com/94

2강 - Docker 설치 & 이미지와 컨테이너 개념
컨테이너(container)란?
다운로드 받은 이미지(image)를 실행 중인 리눅스 기반 가상 컴퓨터

터미널창 도커 관련 명령어 
1) 현재 다운로드 받은 도커 이미지 목록 출력
docker image ls

2) 도커 이미지 다운로드 받기 
docker pull hello-world

3) 도커 이미지 실행 
docker run 이미지이름:태그
(예) docker run hello-world:latest

3강 - Docker로 띄워볼 서버만들기

4강 - Dockerfile 명령어 & 이미지 만들기
Dockerfile 명령어
1) FROM node:22-alpine
이런걸 기재하면 Node.js 22버전과 alpine 리눅스 OS가 설치된 채로 시작.

2) FROM node:20-slim
Node.js 20버전 설치된 채로 시작 (윈도우 OS)

3) FROM scratch
참고로 바이너리로 컴파일한 파일만 돌리면 되는 경우엔
OS 설치가 딱히 필요없을 수 있는데 그럴 땐 빈 도화지에서 시작하라고 이런걸 쓰기도 합니다.

4) RUN npm install express
RUN 뒤에 있는걸 터미널 명령어처럼 실행(express 라이브러리 설치)

5) COPY 내컴퓨터파일경로 이미지내부파일경로 
내 컴퓨터에 있던 파일을 이미지로 복사
COPY 명령어 뒤에는 경로 2개를 적을 수 있는데
왼쪽에는 내컴퓨터 폴더경로, 오른쪽에는 이미지 어디로 옮길건지 정하면 됩니다.
(예) COPY . .
마침표(.)는 현재 경로라는 뜻이기 때문에
Dockerfile 현재경로 옆에 있던 모든 파일과 폴더들을 가상컴퓨터 현재경로로 복사해달라는 뜻입니다.
그러면 소스코드도 전부 복사되어서 편하겠군요.
근데 이러면 node_modules같은 라이브러리 소스코드도 복사해줄텐데 굳이 그건 복사할 필요는 없습니다.
복사하기 싫은 파일이 있으면 아래처럼 .dockerignore 파일 만들어서 파일이나 폴더경로 기재해두면 됩니다.
그러면 아래 3가지 파일(.git, Dockerfile, node_modules)은 복사 대상 제외 처리
.git
Dockerfile
node_modules

6) WORKDIR /app
근데 파일 카피하기 전에 폴더 이동을 좀 해보도록 합시다.
왜냐면 이미지 기본 경로에 옮기면 파일이 좀 많으면 더러울 수 있으니까
/app 같은 폴더 하나 만들어서 거기로 이동하라고 합시다.
쉽게하려면 WORKDIR /app 이러면 됩니다.
그러면 현재 작업경로를 /app 폴더로 바꿔주고 /app 폴더가 없으면 하나 만들어줍니다.
터미널 명령어중에 cd와 비슷한 역할입니다.

7) RUN ["npm", "install"]
그 다음에 npm install을 터미널에서 입력하면 package.json에 기재된 라이브러리가 설치된다고 했으니까
npm install 하라고 명령을 줘봅시다.
RUN npm install 이렇게 써도 되는데 대괄호치는게 더 안정적인 방식입니다.

괄호 안치면 /bin/sh -c npm install 이라는 명령어가 실행이 되는데
이게 뭐냐면 내 OS에 기본적으로 설치된 shell을 이용해서 실행하라는 소리입니다.
그래서 shell이라는 프로그램과 거기서 제공하는 && || 이런 명령어가 필요하면 괄호없이 쓰면 되는데
하지만 shell 기능이 필요없거나 OS마다 shell이 서로 다를 수 있기 때문에 불안하면 대괄호를 씁시다.

8) CMD ["node", "server.js"]
그럼 이제 마지막으로 node server.js 입력하면 파일이 실행되고 그러면 웹서버가 실행됩니다.
그래서 Dockerfile에도 그거 하라고 작성하면 되는데
RUN node server.js 하면 될 것 같은데
하지만 보통 마지막 명령어는 RUN말고 CMD 뒤에 적습니다.

참고사항 - Dockerfile 명령어 CMD vs ENTRYPOINT
CMD vs ENTRYPOINT
나중에 내 이미지를 실행할 때 멋있게 터미널에서 실행하고 싶으면 

docker run 이미지명
입력하면 되는데 근데 뒤에 몰래 명령어를 추가할 수 있습니다.

docker run 이미지명 node server1.js 
그러면 Dockerfile 내의 CMD 부분이
node server1.js로 덮어쓰기가 되어서 실행됩니다.
그래서 매번 다른 명령어로 실행하고 싶으면 CMD 사용하면 덮어쓰기 편리해집니다.

CMD 말고 ENTRYPOINT를 쓰면 기능은 비슷하지만 덮어쓰기가 살짝 어려워집니다.
이상한 명령어를 써야 덮어쓰기가 되기 때문에 
어떻게 보면 ENTRYPOINT쓰면 좀 더 안정적이라고 보면 되겠습니다.

실은 섞어서 써도 됩니다.
변경원하지 않는 부분은 ENTRYPOINT에 넣고
변경원하는 부분은 CMD 넣고 그러셔도 됩니다.

(Dockerfile)

(...생략)
ENTRYPOINT ["node"]
CMD ["server.js"]

예를 들어 이런 식으로 적어두면 
앞으로 이미지 실행할 때 docker run 이미지명 server1.js 이렇게 실행하면
node server1.js 라는 커맨드가 마지막에 실행됩니다.
그래서 docker run 할 때마다 일부 명령어만 가변적으로 덮어쓰기 하고 싶을 때 이런 식으로 써도 되겠습니다.
지금은 쓸데없으니까 아무거나 씁시다.

9) EXPOSE 8080
EXPOSE 명령어 뒤에 8080 이런 식으로 포트번호를 기재할 수 있습니다.

포트가 뭐냐면 컴퓨터에 뚫린 구멍입니다. 
이게 뚫려있어야 외부 사람들이 내 컴퓨터로 접속이 가능해서 웹서버 운영하는 컴퓨터도 포트를 하나 뚫어줘야합니다.
그래서 코드짤 때 8080 이런 포트를 뚫으라고 코드짜놨습니다.

그래서 이미지 돌릴 컴퓨터에도 8080 포트를 오픈하라고 해야하는데 그건 이미지 실행할 때 명령줄 수 있습니다.
근데 위처럼 EXPOSE 8080 이런걸 작성해놓으면 나중에 포트 오픈하라고 명령줄 때 약간 편리합니다.
그래서 편의를 위해 쓰는 메모같은 개념입니다. 없어도 상관은 없음

10) docker build -t 이미지이름:태그 .  
Dockerfile 작성했으면 이걸 바탕으로 이미지를 하나 만들어달라고 명령내릴 수 있습니다.

작업폴더에서 터미널 열어서 입력해봅시다.
- 이미지 이름은 맘대로 작명합시다.
- 태그도 맘대로 작명합시다. 태그는 버전이랑 비슷하게 취급하면 됩니다.
- 마침표자리에는 Dockerfile 경로 입력하면 되는데 마침표(.)는 현재경로라는 뜻입니다.
- 참고로 docker desktop 또는 docker engine이 실행되고 있어야 이거 명령어도 사용가능합니다.

아무튼 그럼 입력하면 커스텀 이미지가 생성됩니다.
이미지 확인은 docker desktop 들어가보거나 터미널에 docker images 입력해봅시다.

* 이미지 실행하기 
위의 docker 명령어 1) ~ 10)번 까지 사용하여 
만든 이미지 실행 잘 되나 확인해봅시다.
재생버튼 누르거나 docker run 명령어 입력하면 되는데
근데 포트 부분에 8080을 기입해서 실행해봅시다.

▲ 누가 내 컴퓨터 8080번 포트로 들어오면 가상 컴퓨터의 8080번 포트로 연결하라는 뜻입니다.
뭔 소리인지는 네트워크 시간에 자세히 알아봅시다.
터미널을 사용할 것이면 docker run -p 8080:8080 이미지명:태그명 입력합시다.

아무튼 브라우저 켜서 localhost:8080으로 들어가보면 웹서버를 만날 수 있습니다.
이게 나만의 커스텀 이미지만들고 실행하는 법 끝입니다.
이제 이 이미지를 다른 컴퓨터로 보내서 실행만 하면 그게 배포 아니겠습니까.

(참고) localhost가 뭐냐면 내 컴퓨터로 접속하라는 뜻입니다.
(참고) 실은 docker init 명령어 입력하면 Dockerfile을 약간 자동완성 해주기 때문에
거기서 필요한거 수정해서 쓰는 방법도 좋습니다.

5강 - 컨테이너 다루기

* 이미지 실행 터미널에서 하려면
docker run -d 이미지명:태그명 (예) docker run nodeserver:1 / docker run -d nodeserver:1

터미널에 입력하면 이미지를 컨테이너에서 실행할 수 있다고 했는데
근데 이러면 터미널 하나를 무단 점유하기 때문에 터미널이 또 필요해지면 하나 더 귀찮게 열어야한다.
그게 싫으면 -d 옵션을 집어넣어서 백그라운드에서 실행가능하다.

여기서 -d 옵션은 detached의 약자이다.

* 이미지 실행시 포트 설정
docker run -p 8081:8080 -d 이미지명:태그명 (예) docker run -d -p 8081:8080 nodeserver:1 / docker run -d -p 8080:8080 nodeserver:1

이미지를 실행할 때 포트를 설정해주고 싶으면 -p 옵션 넣고 내컴퓨터포트:컨테이너포트 집어넣으면 된다.

그래서 위처럼 실행하면 누가 내 컴퓨터 8081 포트로 들어오면 컨테이너의 8080 포트로 안내해주라는 뜻이다.
포트설정 없이 그냥 띄우면 브라우저로 접속했을 때 아무것도 안 뜬다.

하지만 왜 그런지 이유를 알아야 나중에 응용이 되기 때문에
왜 포트 설정을 해야하는지는 그림을 봅시다.

▲ 포트 설정을 안해놨을 때 왜 localhost:8080으로 접속했을 때 아무것도 없냐면
일단 localhost는 내 컴퓨터로 접속하라는 뜻이고
8080은 8080번 포트로 접속하라는 뜻입니다.

근데 거기로 들어가봤자 웹서버는 없음
왜냐면 웹서버는 내 컴퓨터 안의 가상컴퓨터(container)에서 돌아가고 있다.

내 컴퓨터(localhost) 안의 은밀한 곳에서 혼자 돌아가고 있기 때문에
내 컴퓨터(localhost) & 가상컴퓨터(container)의 포트끼리 연결하는 작업을 해주면 된다.

▲ 포트끼리 연결하는건 별거 아니고
"내 컴퓨터(localhost) A번 포트로 들어오면 컨테이너(가상컴퓨터(container))의 B번 포트로 보내라" 이건데
이걸 하고 싶으면 컨테이너 실행할 때 -p 내컴퓨터포트번호:컨테이너포트번호 하면 된다.
똥배관 연결같은 것임

Q. 다른 컴퓨터 접속은 어떻게 하는 것임?

그니까 지금 계속 다른 사람들이 내 컴퓨터에 접속한다고 했는데 그건 어떻게 하는것이게요?
실은 웹브라우저 켜서 어떤컴퓨터IP주소:포트번호 입력하면 그게 다른 컴퓨터에 접속하는 법이다.

내가 내 컴퓨터에 접속하는 방법도 있다.
내컴퓨터IP주소:포트번호 입력하면 되는데
번거롭게 IP주소 찾을 필요 없이 내 컴퓨터는 localhost라고 입력하면 된다.

그래서 남의 입장이 되어서 내 컴퓨터로 들어가는걸 시뮬레이션 해보려면
브라우저에 localhost:8080 이런거 입력해보는 것이다.

* 컨테이너 관련한 명령어들

이미지를 실행중인 컨테이너 관련한 명령어 몇개만 알아봅시다.

docker ps
현재 실행중인 컨테이너들을 살펴볼 수 있다.
(예) docker ps 터미널 실행 결과 
CONTAINER ID   IMAGE          COMMAND                   CREATED         STATUS         PORTS                    NAMES
3ab1acf87523   nodeserver:1   "docker-entrypoint.s…"   6 minutes ago   Up 6 minutes   0.0.0.0:8080->8080/tcp   keen_gauss

docker logs 컨테이너이름
컨테이너 컴퓨터 터미널의 로그 출력이 가능하다.
(예) docker logs keen_gauss 터미널 실행 결과 
서버 실행중 http://localhost:8080

docker exec -it 컨테이너이름 sh 
특정 컨테이너 터미널로 접속이 가능하다.
그럼 이제 명령어 입력할 때 마다 그 컨테이너 터미널 안에서 실행이 된다.
진짠지 궁금하면 들어가서 파일목록 보여주는 ls 명령어 입력해봅시다.
컨테이너를 탈출하려면 ctrl +p 후에 ctrl + q 입력한다.
(예) docker exec -it keen_gauss sh 터미널 실행 결과 
(터미널창에 # 출력되면 명령어 "ls" 추가 입력 및 엔터)
현재 폴더 파일 목록 보기 
# ls 
node_modules  package-lock.json  package.json  server.js  study.text
(터미널창에 # 출력되면 명령어 "cd .." 추가 입력 및 엔터)
파일 경로 이동 및 폴더 파일 목록 보기
# ls
app  bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr                                                                                                    v
ar

docker stop 컨테이너이름
실행중인 컨테이너 정지해줌. 컨테이너 아이디 입력해도 된다.
(예) docker stop keen_gauss 터미널 실행 결과 
keen_gauss

docker rm 컨테이너이름
정지된 컨테이너를 삭제해줌. 정지안된 컨테이너 삭제하려면 -f 옵션을 붙여준다.
(예1) docker rm keen_gauss
(예2) docker rm keen_gauss -f

이런 식으로 쭉 나열해봤는데
뭔가 많이 배운거같은 느낌 주려고 한거고
어짜피 다음날 다 까먹기 때문에 그냥 이런게 있다고만 알고 지나가면 된다.

필요할 때 찾아서 쓰자.
위 명령어들은 docker desktop 안에서 container 메뉴 들어가면 전부 클릭질로 할 수 있게 되어있다.

* 컨테이너 구조
컨테이너의 실체같은게 궁금하면 별거 아니다.
리눅스 OS가 제공하는 이거저거 기능을 섞은 것이다.

리눅스의 namespace 기능을 사용하면
프로그램마다 서로 영향을 끼치지 않게 독립적으로 프로세스와 파일구조 같은걸 분리해줄 수 있다.

리눅스의 cgroup이라는 기능을 사용하면
프로그램마다 CPU나 램을 얼마나 점유할 건지도 정해둘 수 있다.

이런걸 이용하면 혼자 별도로 독립적으로 동작하는 가상 컴퓨터를 만들 수 있는데 그걸 "컨테이너"라고 멋있게 포장해서 부를 뿐이다.

컨테이너는 여러개 띄울 수 있어서 컴퓨터 한 대에서 여러 컴퓨터를 운영하는 것 처럼 마법을 부릴 수 있고
컨테이너에서 문제가 생겨도 내 컴퓨터로 전염되는 일이 거의 없고
그런 장점이 있다.

원래 runc같은 프로그램을 쓰면 컨테이너를 띄울 수 있다.
실은 containerd라는 프로그램으로 runc를 조작하면 편리해서 그런 경우들도 있다.
그럼 Docker는 뭐냐면 containerd, runc를 7살짜리도 쓸 수 있게 만든 프로그램일 뿐이다.
거기에 이미지 빌드기능, pull 기능, 관리기능 이런걸 더해서 개발자들 편하게 만들어준 것임

그래서 Docker대신 다른 프로그램 사용해도 된다.
Podman 이런 것도 유명하고 맥북의 경우 Orbstack 이런게 최근에 가볍다고 유행하던 것 같다.

6강 - 성능을 위한 Dockerfile 작성법

* 좋은 관습 1. 캐싱
프로젝트가 커지면 docker build 입력해서 기다리는 시간도 끔찍해지는 경우가 있다.
그러면 배포할 때마다 docker build 입력해야할텐데 그 때마다 속터져 죽는다.

죽기 싫으면 좋은 방법이 하나 있는데 그게 뭐냐면 
Dockerfile 작성시 "빌드할 때마다 변동사항이 많이 생기는 부분들을 최대한 아래 쪽에 적기"이다.
그럼 build 시간이 단축될 수 있다.


Q. 밑에 적는걸로 뭐가 빨라짐?

원래 빌드작업할 때 COPY, RUN 명령을 실행할 때 마다 도커가 몰래 캐싱을 해놓는다.
캐싱은 결과를 몰래 저장해놓고 나중에 필요해지면 재사용한다는 소리이다.

- 캐싱된 명령어들은 매우 빠르게 처리해줄 수 있다.
- 변동사항이 생긴 명령어부터는 캐싱된걸 사용하지 않는다.
- 그럼 변동사항이 많은건 좀 아래쪽으로 내리면 좋다.

 
예를 들면 Node.js로 웹서버 개발하는 경우는
package.json 내용이나 npm install로 라이브러리 설치하는건 날마다 변동사항이 거의 없다.
(라이브러리를 매일매일 설치하진 않지 않습니까)

그래서
1. OS와 Node.js 설치하고
2. package.json 먼저 옮겨서 라이브러리 설치부터 먼저 하고
3. 그 다음에 자주 변동되는 소스코드 옮기고
...

그런 식으로 Dockerfile을 작성하면 매번 docker build 할 때 약간이라도 더 빨라질 수 있는 것이다.

(예) Dockerfile 명령어 작성 예시
FROM node:20-slim
WORKDIR /app
COPY package*.json .
RUN ["npm", "install"]

COPY . .
EXPOSE 8080
CMD ["node", "server.js"]
그래서 이렇게 고쳐봤습니다.

이제 빌드할 때 마다 뭔가 빨라진 느낌이 들 수 있는데 지금은 별차이 없다.

* 좋은 관습 2. npm ci
(예) Dockerfile 명령어 npm ci 예시
RUN ["npm", "ci"]

Dockerfile 작성시 좋은 관습을 몇개 알아보자.
Node.js 개발할 때 라이브러리 정확한 버전 설치하려면 npm install 말고 npm ci 라는 커맨드를 쓰는 것도 좋다.
그냥 npm install하면 package.json에 기록된게 설치되긴 하는데

"express" : "^4.21" 가끔 이런 식으로 표기되어있으면 맨 앞자리가 4만 되면 된다는 뜻이라서
나중에 라이브러리가 업데이트되면 실수로 4.22 버전이 막 설치되고 그럴 수 있다.

그래서 이거 ^ 표시를 지우거나 아니면 package-lock.json에 내가 쓰는 라이브러리의 정확한 버전이 써있기 때문에
그걸 바탕으로 설치하라고 입력하는게 npm ci 이다. (package-lock.json 파일 바탕으로 설치하는 명령어가 RUN ["npm", "ci"] 이다.)

심심하면 Dockerfile을 그렇게 수정해보자.

* 좋은 관습 3. ENV

(예) Dockerfile 명령어 작성 예시
ENV NODE_ENV=production
CMD 어쩌구~

ENV 라는 명령어를 쓰면 환경변수를 집어넣어서 이미지를 빌드할 수 있다. 

ENV 환경변수이름=값 사용하면 된다.
이런걸 왜 쓰냐면 옛날부터 존재하던 express 같은 라이브러리들은

NODE_ENV=production을 집어넣어놔야 로그출력양을 좀 줄이고 그래서 성능이 향상되고 그런 케이스가 있다.
그래서 Node.js 개발시 설정해두면 나쁠건 없다.
참고로 docker run할 때도 -e 옵션으로 환경변수를 그때그때 집어넣어서 이미지를 실행할 수 있다.

* 좋은 관습 4. 권한 낮추기

보안적으로 더 나은 습관도 있는데
원래 Dockerfile에 적은 명령어들은 전부 root 권한으로 실행된다.

마지막에 서버 띄우는 명령어는 root 말고 권한을 좀 낮춰서 실행하는게 약간 더 안전하고 좋다.
그럴려면 유저를 하나 생성하고 그걸로 유저를 바꿔서 실행하라고 코드짜면 되는데
근데 node 공식 이미지의 경우엔 node라는 이름의 유저가 이미 만들어져있다. 

그래서 그거 써도 된다.

(Dockerfile)

USER node
CMD 어쩌구~
USER 유저이름 적으면 그 유저로 변경된다.

유저가 제공되지 않는 이미지는 직접 유저만드는 명령어 찾아서 쓰자.
참고로 실은 지금 하는 것들은 친절한 node 공식 이미지 설명서에 다 나와있는 것들이라
이런건 어디서 배워야 알 수 있는 건 아니고 찾아보면 나온다.
https://github.com/nodejs/docker-node/blob/main/docs/BestPractices.md

* Spring boot 프로젝트의 경우

Spring boot로 만든 웹서버가 있으면 그건 어떻게 이미지로 만드는지 알아보자.
Spring boot 모르면 그냥 취미로 들어보자.

Spring boot 서버를 실행하려면

1. 터미널에서 ./gradlew build 입력해서 .jar파일을 만들고
2. 터미널에서 java -jar .jar파일경로 입력해서 .jar 파일 실행하면 끝이다.

매우 간단한 편이라 Dockerfile도 저렇게 작성하면 이미지 생성 끝이다.

# 1. 터미널창에서 ./gradlew build를 입력해서 .jar파일 생성  

# 2. 새롭게 OS 다시 설치
FROM amazoncorretto:21.0.4
# 3. 거기에 .jar 파일만 옮김
WORKDIR /app
COPY . .
RUN ./gradlew build
# 4. java -jar .jar 파일 실행
CMD ["java", "-jar", ".jar파일경로"] 

프로젝트 폴더에 Dockerfile 만들고 이런거 작성하는게 끝이다.

- Java 21버전으로 설치했는데 여러분이 쓰던 버전으로 설치하면 된다.
- 아마 .jar 파일은 /build/libs 폴더에 생성되어있을 것이다.

근데 용량을 더 줄이고 싶으면 이런 편법을 써도 되는데
실은 생성된 .jar 파일만 있으면 서버를 돌릴 수 있기 때문에 다른 소스코드나 그런건 전혀 필요없다.

그래서 .jar 파일 하나만 담은 이미지를 생성해서 그것만 실행하라고 Dockerfile을 작성하면
이미지 용량을 훨씬 작게 만들 수 있다.

1. 터미널에 ./gradlew build를 입력해서 .jar파일을 만들기
2. 새로운 이미지를 만들어서 그 .jar 파일을 새로운 이미지로 옮기기
3. 명령어로 .jar 파일을 실행하기

이렇게 작성하면 되는 것임

* multi-stage build

# OS, Java 21 버전 설치한 이미지 불러오기
FROM amazoncorretto:21.0.4 AS build
# 폴더 app 이동
WORKDIR /app
# 소스코드 옮기기(복사)
COPY . .
# 명령어 ./gradlew build 실행 -> .jar 파일 생성 
RUN ./gradlew build

# Runtime stage
# OS 새로 설치 및 Java 21 버전 새로 설치한 이미지 불러오기 
FROM amazoncorretto:21.0.4 AS runtime
# 폴더 app 이동
WORKDIR /app
# 기존 이미지 .jar 파일(/app/build/libs/*.jar)을 현재 이미지 경로 이동(/app/server.jar)
# 명령어 COPY --from=build 실행(기존 이미지에서 생성된 파일을 현재 이미지로 COPY 가능)
COPY --from=build /app/build/libs/*.jar /app/server.jar
CMD ["java", "-jar", "/app/server.jar"] 

실은 Dockerfile에 FROM을 2번 이상 작성할 수 있는데
FROM을 만날 때 마다 위에 있는 작업내역들이 삭제되고 새로운 마음으로 깨끗하게 시작된다.

근데 깨끗하게 시작할 때 위의 작업내역에서 만든 파일들을 몰래 훔쳐올 수 있다.
이게 비결임

첫째 FROM에선 /app 폴더에서 .jar 파일만 만들어준다.
두번째 FROM에선 이전 FROM에서 나온 .jar 파일을 /app/server.jar 경로로 훔쳐오라고 했다.

--from=build 이러면 build라고 이름지은 곳에 있던 파일을 카피하라는 뜻이다.
(AS 명령어 쓰면 FROM마다 이름을 마음대로 붙일 수 있다.)

그 다음에 마지막에 .jar 파일을 실행하는것이다.
그럼 이제 최종 이미지에는 .jar 파일, 리눅스OS, 자바21 JDK 이 정도만 들어있어서 좀 가벼워졌겠군요.

FROM 여러번 쓰는 짓거리를 multi-stage build 라고 하는데
그래서 빌드과정이 필요한 프로젝트들은 이런 식으로 작성해서 용량을 줄이고 보안도 약간 챙길 수 있다.

* bootBuildImage 명령

실은 Spring boot에서 gradle을 쓰는 경우에는 이미지 만드는 명령어가 아마 내장되어있다.
터미널에 ./gradlew bootBuildImage 입력하면 이미지를 자동으로 만들어주기 때문에
Dockerfile 작성 귀찮으면 한 번 사용해보자.

* Next.js 프로젝트는

Next.js 프로젝트도 코드를 다 짰으면 npm run build 명령어 입력하고 npm start 이런 걸로 코드를 실행해야한다.

그래서 빌드 과정이 필요하기 때문에
이것도 Dockerfile 작성할 때 multi-stage build 잡기술을 이용하면 용량을 더 줄일 수 있다.

근데 그것보다 더 간편한게 있는데 nextjs output standalone 같은거 검색해보자.
그러면 배포할 때 꼭 필요한 파일만 알아서 남겨준다.

오늘의 결론은 
Dockerfile 작성할 때 잡기술 넣으면 여러 장점이 있다.

그리고 성능이나 최적화에 집착하면 고수처럼 보일 수 있다.

7강 - Docker hub, push, pull

* 리포지토리 만들기 
Docker hub 사이트에 방문해봅시다. (hub.docker.com)

▲ 가입하고 로그인해보면 리포지토리를 만드는 버튼이 어딘가에 있을텐데 눌러보자.
리포지토리는 "이미지 보관용 폴더"이다.

▲ 리포지토리 이름 작명하고 public이 무료라 그걸로 선택하면 된다.
(대신 public은 아무나 볼 수 있다)
그리고 오른쪽에 이미지 업로드하는 방법 그대로 따라하면 업로드 가능하다.

이미지 업로드하는 방법
Pushing images
You can push a new image to this repository using the CLI:

docker tag local-image:tagname new-repo:tagname
docker push new-repo:tagname

Make sure to replace tagname with your desired image repository tag.

* 이미지 업로드는 docker push

저번에 만든 이미지 하나를 저기 방금만든 리포지토리에 올려보자.
없으면 이미지 아무거나 도커허브에서 다운받아서 올려보자.

docker tag 이미지이름:태그명 리포지토리이름:태그명작명 (이미지 이름을 바꾸는 명령어)
docker push 리포지토리이름:태그명작명 (이미지를 도커허브 리포지토리에 올리는 명령어)

일단 이미지 올리려면 터미널 명령어가 2개 필요한데 
첫째는 일단 이미지 이름을 바꾸는 명령어고
두번째가 이미지를 도커허브 리포지토리에 올리는 명령어이다.

이미지 이름부터 바꿔야 하는 이유는
원래 이미지 이름에 정확히 그 리포지토리 이름이 들어가야 리포지토리에 올릴 수 있다.

▲ 저는 리포지토리 이름을 minjaejeon0827/myserver 이렇게 만들었기 때문에

docker tag nodeserver:1 minjaejeon0827/myserver:1
docker push minjaejeon0827/myserver:1
이런 식으로 이미지 이름을 바꾸고 올려봤다.

뭔가 안된다고 나오면 터미널에 docker login부터 입력해서 로그인 하라는거 해보시면 된다.

명령어 docker tag nodeserver:1 minjaejeon0827/myserver:1 실행시
Docker 응용 프로그램 -> 화면 좌측 버튼 "Images" 클릭 -> 화면 "Images" 이동 -> 해당 화면 중앙 이미지 목록에서 
▲ 참고로 docker tag 이용해서 이미지 이름을 바꾸면
이미지 목록에 이미지가 하나 더 추가된다. (이미지 minjaejeon0827/myserver 추가 )

그래서 뭔가 용량도 2배 차지하게 되고 그럴 것 같은데 ID가 동일(Image ID - a603f7baee64)하면 실은 같은 이미지이다.

원래 이미지는 여러개의 이름을 가질 수 있다.
해당 화면 중앙 이미지 목록은 그냥 모든 이미지 이름을 보여주는 곳이라고 보면 된다.

* pull하기

docker pull 이미지명:태그
이미지를 docker hub에서 내려받으려면 docker pull 명령어를 쓰면 된다.
(예)
docker pull minjaejeon0827/myserver:1
docker pull minjaejeon0827/myserver:2

실은 docker desktop 에서도 올리고 내려받을 수 있기 때문에 그런 식으로 써보셔도 된다.

Q. 이미지 업데이트된거 올리고싶으면?
- 태그명을 다르게 작성해서(minjaejeon0827/myserver:2) 이미지 새로 빌드하고(minjaejeon0827/myserver:2) 올리면 된다.
(예)
docker tag nodeserver:1 minjaejeon0827/myserver:2
docker push minjaejeon0827/myserver:2

Q. 다른 종류의 이미지도 업로드하고 싶으면?

예를 들어 서버 담은 이미지, 프론트엔드 담은 이미지, DB 담은 이미지 이런게 있으면
각각 어디에 업로드하는게 좋을까.

- 이런 경우엔 각각 별도의 리포지토리를 만들어서 거기에 업로드하는 경우들이 많다.
근데 귀찮아서 혹은 private 리포지토리 하나가지고 계속 쓰고 싶어서 하나의 리포지토리에 태그명만 다르게 해서 쑤셔넣는 경우도 있다.

하지만 이미지 종류마다 별도의 리포지토리를 만드는게 깔끔하다.

(참고) 리포지토리 만들 때 private 말고 public 으로 만들면 아무나 이걸 다운받을 수 있기 때문에
좀 민감한 내용이 들어있는 것들은 private 리포지토리에 올려두면 된다.

하지만 private 리포지토리는 계정마다 1개만 생성가능하다.

8강 - Network 1. nginx 만들기

* nginx
웹서버와 함께 돌리면 매우 좋은 프로그램이 하나 있다.
reverse proxy라고 하는데 서버로 들어오는 요청을 중간에 가로채주는 간단한 프로그램이다.

▲ 그걸 쓰면 유저들이 서버로 직접 들어오게 하는게 아니라
리버스 프록시 프로그램(nginx)으로 먼저 들어오게 하고
리버스 프록시가 유저를 다시 서버로 안내하는 식으로 만들어놓는다.

왜 그따구로 비효율적인 프로그램을 띄워놓냐면

- 서버의 정체를 안전하게 숨기기 가능
- HTTPS 인증서 설치 쉬움
- 서버가 여러개면 로드 밸런싱 가능
- 누가 접속했는지 로그도 남기기 쉬움
- IP 차단 쉽게가능

그래서 사용한다.
리버스 프록시 프로그램은 nginx 아니면 caddy 이런게 유명한데 우리는 nginx라는 리버스 프록시 프로그램을 써보도록 하자.

* nginx
이것도 이미지 만들어서 컨테이너로 실행해볼 것인데
그럴려면 nginx를 로컬컴퓨터에서 설치하고 셋팅하는 방법도 아는게 좋겟죠?
그래야 Dockerfile을 작성하든 할 것 아닙니까

여러분들 컴퓨터에서 nginx 설치하고 실행하려면

1. 컴퓨터에 nginx 설치 
참고 URL - https://nginx.org/
참고 2 URL - https://wikidocs.net/223824
참고 3 URL - https://bakingdevlog.tistory.com/13
참고 4 URL - https://jettstream.tistory.com/527

2. 동작방식을 .conf 파일에 맘대로 작성해서 설치폴더에 집어넣기
3. 터미널에 nginx -g daemon off; 입력해두면 nginx 실행

우선 .conf 파일은 어떻게 작성하는지 맛을 먼저 보도록 하자.

* .conf 파일 사용법
(myconfig1.conf)

server {
        listen 80;
        location / {
            proxy_pass http://localhost:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
}

아무 폴더 하나 만들어서 어쩌구.conf 파일을 안에 만들고 위에 있는 대충 기본적인 설정들을 복붙해보자.

- listen 80은 누가 80번 포트로 들어오면 밑에 있는 내용을 실행하라는 뜻이다.
- location / { } 부분은 누가 /로 시작하는 모든 경로로 들어오면 localhost:8080으로 보내라는 뜻이다.
- proxy_set_header 부분은 header라는 부분에 IP 주소 등 여러 정보를 채우라는 뜻인데 심심해서 넣어봤다.

그리고 이 설정파일을 특정 폴더에 넣어줘야한다.
리눅스에 nginx를 설치했으면 /etc/nginx/conf.d/ 폴더에 넣어주면
그러면 nginx가 알아서 .conf 파일을 가져가서 사용해준다.


정확히말하면 /etc/nginx/conf.d/어쩌구.conf 파일은

nginx.conf 라는 기본 설정파일의 http { } 안에 자동으로 넣어서 실행됩니다.

(예) nginx.conf
http {
    (여기 넣어줌)
}

근데 사소한 문제가 있는게
/etc/nginx/conf.d/default.conf 이라는 파일이 자동으로 생성되어있는데
그게 여러분들이 작성한 설정보다 먼저 적용될 수가 있다.

그래서 기본설정은 쓸데없으니까 그 파일은 삭제하면 된다. 
덮어써도 되고 삭제해도 된다.

* 이미지 빌드하기
그래서 dockerfile 이용해서 nginx 이미지를 한번 만들어보도록 하자.
nginx 설치하고 설정하고 실행하는거 그대로 Dockerfile에 써놓고 빌드하면 된다.

(예) (Dockerfile)

FROM nginx:latest

COPY ./myconfig1.conf /etc/nginx/conf.d/myconfig1.conf
RUN rm /etc/nginx/conf.d/default.conf

EXPOSE 80
CMD ["nginx", "-g", "daemon off"]

- nginx 설치하고
- Dockerfile 옆에 만들어둔 myconfig1.conf 설정파일을 리눅스의 /etc/nginx/conf.d/에 복붙하고 
- 기본설정파일은 삭제하고 
- nginx 실행하라고 했다.

docker build -t nginx:1 . 
터미널에서 nginx라는 이름으로 이미지를 빌드도 해봤다.

▲ 이미지 실행도 해보자.
누가 내 컴퓨터 80번 포트로 들어오면 이 컨테이너 80번 포트로 안내하라고 해봤다.
그럼 이제 localhost:80으로 접속해보면 뭔가 이상한게 나올텐데 그럼 성공이다.

nginx 설정에다가 누가 80번포트로 접속하면 localhost:8080으로 안내하라고 코드짜놨으니까
그럼 이제 localhost:8080에 웹서버를 띄워놓으면 의도대로 리버스 프록시처럼 잘 동작하지 않을까요?

▲ 그래서 전에 만든 웹서버도 8080포트에 컨테이너로 띄워봤다.
그럼 이론상 localhost:80 접속하면 localhost:8080에 있는 서버가 떠야하는데 아무것도 안뜨는데요?

▲ 그 이유는 그림으로 보시면 지금 가상컴퓨터 2대를 띄워놨고
내 컴퓨터의 포트도 거기에 각각 연결해뒀다.
왼쪽 nginx 가상컴퓨터에는 "누가 80번 포트로 들어오면 8080포트로 보내기" 라고 코드를 짜놨다.
하지만 왼쪽 nginx 가상컴퓨터에는 8080포트에서 동작중인 프로그램이 없는데요?
그래서 내 컴퓨터 80번 포트인 localhost:80으로 들어가도 아무것도 안나오고 에러가 나는 것일 뿐이다.

Q. 오른쪽 가상컴퓨터에 8080포트에 웹서버 돌아가고 있는데요?

- 그건 nginx와 상관없는 다른 별도의 컴퓨터일 뿐이다.
그래서 누가 "80번 포트로 들어오면 옆에 있는 가상 컴퓨터의 8080번 포트로 보내기" 이렇게 코드를 짜면 잘 동작합니다.
그럼 다른 가상컴퓨터로 접속하는 법을 알면 되겠네요.

* 다른 가상컴퓨터로 접속하려면
어떤 가상컴퓨터에서 다른 가상컴퓨터로 접속하려면 이런 방법도 있습니다.
내 컴퓨터랑 가상컴퓨터랑 포트를 연결해놨기 때문에

▲ "누가 80번 포트로 접속하면 다시 올라가서 내 컴퓨터의 8080번 포트로 들어가라"
이렇게 역류하는 식으로 짜도 되긴 한다.

▲ 근데 이것보다 더 안전하고 간단하게 하려면 network 라는걸 만들어서 그 안에 가상 컴퓨터를 담아놓아도 된다.
같은 network 안에 들어있는 가상 컴퓨터들은 서로 쉽게 통신이 가능해진다.

왜냐면 network 안에 집어넣으면 가상 IP주소를 부여해주기 때문에
가상IP주소:8080 이런 식으로 사용하면 다른 가상컴퓨터에 접속가능하다.

다음 시간에 해보자.

9강 - Network 2. 컨테이너간 통신

컨테이너들은 각각의 독립적인 컴퓨터기 때문에 원래 서로 만나고 그럴 수가 없다.
근데 네트워크를 만들어서 그 안에 집어넣으면 서로 만날 수 있다.
왜냐면 네트워크에 컨테이너를 넣으면 컨테이너마다 가상 IP 주소를 부여해준다.
그래서 컨테이너가 다른 컨테이너로 접속하고 요청날리고 그러고 싶으면 가상 IP 주소를 사용하면 되는데
엄마가 남의 말 믿지 말랬으니까 직접 네트워크를 하나 만들어보자.

* 네트워크 만들기
docker network create 네트워크이름작명
터미널에서 이런걸 입력하면 네트워크를 하나 가상으로 만들 수 있다.
저는 mynet1 이라는 네트워크를 만들어봤음
(예) docker network create mynet1

docker network ls  

만들어둔 네트워크 목록 조회도 가능하다.

컨테이너를 네트워크에 넣으려면
- 이미 실행중인 컨테이너를 네트워크에 집어넣을 수도 있고
- 아니면 애초에 컨테이너 실행할 때 네트워크에 넣으라고 코드짤 수도 있는데
후자로 해보자.

실행중인 컨테이너 끄고 터미널 명령어를 이용해서 컨테이너를 띄워보자.

docker run -d -p 80:80 --network mynet1 --name nginx-container nginx:1 
docker run -d -p 8080:8080 --network mynet1 --name nodeserver-container nodeserver:1 

컨테이너 실행할 때 "네트워크 안에 담아주세요" 하고 싶으면 
--network 네트워크이름 이용하면 된다.
--name 컨테이너이름 사용하면 컨테이너 이름도 맘대로 정할 수 있다.
컨테이너 이름도 이번 기회에 한번 지어보자. 그럼 컨테이너가 좋아하지 않을까요. 

▲ Docker desktop에서 컨테이너(nginx-container) 상세내용을 살펴볼 수 있는데
Inspect 메뉴 들어가보면 지금 컨테이너(nginx-container)가 어떤 네트워크에 속해있는 지도 검사해볼 수 있다.
사진 보면 mynet1 이라는 네트워크에 속해있고 가상 IP주소도 172.18.0.2가 부여되었다. 
같은 네트워크 안에 있는 컨테이너들은 172.18.0.2로 이 컨테이너를 찾을 수 있다.

(예1) nginx 컨테이너: Docker desktop -> Containers -> nginx-container -> Inspect 메뉴 -> "Networks" 항목 json 데이터
		"Networks": {
			"mynet1": {
				"IPAMConfig": null,
				"Links": null,
				"Aliases": null,
				"MacAddress": "8e:df:7a:b7:5a:66",
				"DriverOpts": null,
				"GwPriority": 0,
				"NetworkID": "6e299d8f353d64df95b00daeaff65fb8ce148b316bae8c092b48b0bf76253c76",
				"EndpointID": "51904350ec438665eb9aee2d57fa634cc51a179f6e7bfb73ccd5d88f30b009a2",
				"Gateway": "172.18.0.1",
				"IPAddress": "172.18.0.2",
				"IPPrefixLen": 16,
				"IPv6Gateway": "",
				"GlobalIPv6Address": "",
				"GlobalIPv6PrefixLen": 0,
				"DNSNames": [
					"nginx-container",
					"9cb6c234a794"
				]
			}
		}

(예2) 웹서버 컨테이너: Docker desktop -> Containers -> nodeserver-container -> Inspect 메뉴 -> "Networks" 항목 json 데이터 
		"Networks": {
			"mynet1": {
				"IPAMConfig": null,
				"Links": null,
				"Aliases": null,
				"MacAddress": "82:18:49:07:ad:2c",
				"DriverOpts": null,
				"GwPriority": 0,
				"NetworkID": "6e299d8f353d64df95b00daeaff65fb8ce148b316bae8c092b48b0bf76253c76",
				"EndpointID": "6194442e056319e21b6cd23cc2ae98f13d440b08b850143e49dfcd073a3fd80d",
				"Gateway": "172.18.0.1",
				"IPAddress": "172.18.0.3",
				"IPPrefixLen": 16,
				"IPv6Gateway": "",
				"GlobalIPv6Address": "",
				"GlobalIPv6PrefixLen": 0,
				"DNSNames": [
					"nodeserver-container",
					"52c497ac57cc"
				]
			}
		}

* 통신하기 
컨테이너끼리 통신이 진짜 되나 확인하려면
하나의 컨테이너로 들어가서 거기다가 다른 컨테이너를 불러보면 된다.

docker exec -it 컨테이너이름 /bin/sh

터미널에서 이런거 입력하면 그 컨테이너의 터미널로 들어갈 수 있다.
혹은 Docker desktop에서 Containers -> 컨테이너 nginx-container 클릭 -> Exec 메뉴 들어가면 됩니다.
그래서 아래처럼 nginx 컨테이너 터미널로 들어가봤다.
docker exec -it nginx-container /bin/sh

curl 웹서버컨테이너IP (예) curl 172.18.0.3:8080
curl 컨테이너 이름    (예) curl server-container:8080
curl 컨테이너이름.네트워크이름

nginx 컨테이너 터미널에서 위처럼 입력해보자.
curl이 뭐냐면 그냥 특정 도메인이나 IP 주소로 접속할 때 쓰는 명령어이다.
그러면 뭔가 뜨지 않습니까? 그러면 통신 된다는 소리이다.

실은 IP주소 말고 curl 컨테이너 이름을 입력해도 아마 잘될 것이다.
왜냐면 컨테이너 이름을 입력하면 그걸 자동으로 IP주소로 바꿔주는
DNS라는 프로그램을 내부적으로 실행하고 있기 때문에 그런 것임
더 정확히 하려면 curl 컨테이너이름.네트워크이름 이렇게 써도 된다.

* 다시 nginx와 웹서버 연동

아무튼 다시 돌아가서
nginx에서 웹서버(nodeserver)로 통신이 되도록 고쳐보자.
이제 nginx 들어오면 웹서버 컨테이너로 보내라고 코드짜려면 
myconfig1.conf 파일을 아래처럼 수정하면 된다.

혹은 웹서버컨테이너IP 대신 웹서버 컨테이너의 이름만 넣어도 된다.
진짜 잘 되는지 이미지 빌드하고 실행도 해보고 nginx주소로 접속해보자.
그럼 웹서버가 잘 뜨면 성공이다.

server {
        listen 80;     # - listen 80은 누가 80번 포트로 들어오면 바로 밑에 있는 내용 실행.
        location / {   # - location / { } 부분은 누가 /로 시작하는 모든 경로로 들어오면 웹서버(웹서버컨테이너IP:8080)로 보내기.(proxy_pass http://웹서버컨테이너IP:8080;)
            proxy_pass http://웹서버컨테이너IP:8080;
            # 웹서버(웹서버컨테이너IP:8080)에 도움되는 유저의 부가정보(proxy_set_header) 채우기.
            # - proxy_set_header 부분은 header라는 부분에 IP 주소 등 여러 정보 채우기.
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
}

(참고) 웹서버 컨테이너의 경우에는 nginx에서 접속하면 끝이라
내 컴퓨터인 호스트와 포트 연결작업이 필요없다.
그래서 웹서버 컨테이너 띄울 때는 -p 옵션은 빼도 되지 않을까요.

* bridge모드, host 모드

기본적으로 network를 하나 만들면 bridge 모드로 만들어 준다.

그거 말고 host 모드로도 네트워크를 만들 수 있는데
그러면 가상컴퓨터들이 내 실제 컴퓨터에서 돌아가는 프로그램처럼 네트워크 자원을 마구 사용할 수 있다.

근데 그 정도의 권한을 가져야하는 프로그램은 거의 없기 때문에 별로 쓸 일은 없고
그냥 기본적으로 생성되는 bridge모드로 네트워크를 만들어서 쓰면 된다.

왜냐면 대충 포트를 마구 열어버리거나 그러면 누가 침입할 수 있는 기회를 마련해주는 것이므로
포트 오픈은 최소화하는게 좋다. 

오늘의 결론은
1. nginx 같은 리버스 프록시 쓰면 웹서버 운영할 때 도움됨
2. 네트워크 안에 컨테이너 넣으면 네트워크에 속한 컨테이너끼리 서로 쉽게 통신가능

10강 - Volume 사용법과 PostgreSQL DB 띄우기

Volume 사용법을 배워볼 것인데 데이터베이스(DB)를 컨테이너로 실행해보면서 다뤄보자.
DB도 직접 설치하고 실행하고 그런 방법을 알면
직접 Dockerfile 작성해서 이미지로 만들어서 띄워도 되긴 하는데
근데 DB는 딱히 설정할게 없으면 직접 이미지로 만들 필요는 없고
미리 만들어진 공식 DB 이미지 같은거 실행만 해도 쉽게 쓸 수 있다.

* PostgreSQL 이미지 다운받기
요즘 인기있는 PostgreSQL을 써보자.
엑셀처럼 테이블에 자료를 저장할 수 있는 관계형 데이터베이스이다.
그러기 위해서 docker desktop 상단에서 postgres 검색해서 원하는 이미지 다운받아오자.
저는 postgres:17-alpine 이런거 다운받아왔다.

▲ 근데 docker desktop 응용 프로그램에서 DB는 실행할 때 환경변수를 채워서 좀 실행해야한다.
아래처럼 DB 접속용 아이디/비번을 환경변수로 채워야한다.
포트바인딩은 하고싶으면 하자.

포트바인딩(Host port) - 5432
환경변수(Environment variables) 
Variable          | Value
POSTGRES_USER     | admin
POSTGRES_PASSWORD | qwer1234

docker run -d --name db-container -e POSTGRES_USER=admin -e POSTGRES_PASSWORD=qwer1234 postgres:17-alpine 
이거말고 터미널에다가 입력하고 postgres DB 실행하고 싶으면 이렇게 하자.
명령어가 길고 더러운데 나중에 docker compose를 배우면 매번 명령어 길게 입력안해도 된다. 

* DB 접속해보기
postgres DB에 접속하려면 DBeaver같은 프로그램 쓰면 좀 비주얼적으로 쉽게 접속해볼 수 있고
아니면 웹서버에서 postgres DB접속해볼 수도 있고
다 귀찮으면 터미널에서 DB접속도 가능하다.

psql이라는 프로그램이 아마 함께 설치될 것이기 때문에 그거 쓰면 터미널에서 DB조작이 가능하다.

docker exec -it 컨테이너이름 /bin/sh

일단 DB 컨테이너 터미널로 들어가보자.
위 명령어를 터미널에 입력하거나
docker desktop에서 DB 컨테이너의 exec 메뉴로 들어가면 된다.


* psql로 DB 다루기
psql은 터미널에서 DB를 조작해볼 수 있는 간단한 프로그램이다.

psql -U admin -W 

PostgreSQL DB 설치된 컨테이너 터미널에 입력하면 DB 접속이 가능하다.
admin자리에는 여러분들 DB접속용아이디 입력하고 -W는 비번 확인하라는 뜻이다.

그러면 비번 입력하라는데 여러분이 설정한 비번 입력하면 된다.
그러면 DB에 접속된다.

\l 입력하면 데이터베이스 리스트를 볼 수 있다.
여기서 데이터베이스라고 부르는건 테이블을 담아놓는 일종의 폴더이다.

\c 데이터베이스명 누르면 거기로 접속할 수 있고
\d 누르면 그 안에 있는 테이블들을 구경할 수 있다. 
테이블은 엑셀파일하나이다.

이제 테이블 하나 만들어서 거기다가 SQL 문법으로 데이터 저장하고 그럴 수 있다.

* 데이터는 volume 써야 유지가능
컨테이너로 DB를 띄우면 문제가 있다.
컨테이너를 껐다켜면 항상 안에 있던 내용이 초기화되기 때문에 DB에 있던 데이터도 당연히 날아간다.
껐다켜도 데이터를 유지하고 싶으면 데이터를 volume에 복사해두면 된다.

▲ Docker desktop 응용 프로그램 왼쪽메뉴보면 volume 메뉴가 있는데 여기서 볼륨을 하나 만들 수 있다.
볼륨이 뭐냐면 "컨테이너에서 발생한 데이터를 백업해둘 폴더"이다.
실은 그냥 하드디스크에 폴더하나 만드는거랑 똑같다. 근데 docker에서 관리해주는 폴더일 뿐임

docker volume create 볼륨이름    # 볼륨 생성 명령어 
docker volume ls                # 볼륨 목록보기 명령어 
docker volume inspect 볼륨이름   # 볼륨 상세보기 명령어 
docker volume rm 볼륨이름        # 볼륨 삭제 명령어

볼륨을 만들어놨으면 이제 컨테이너 데이터를 띄울 때 이 볼륨을 장착할 수 있다.
- 그러면 컨테이너에 있던 데이터는 자동으로 볼륨으로 복사되고
- 나중에 컨테이너 띄울 때 볼륨에 있던 데이터를 컨테이너에 집어넣어서 띄울 수 있다.
이제 컨테이너에 있던 데이터 영구보관이 가능해진다.

* volume 장착해서 DB 컨테이너 띄우기

docker run -v 볼륨이름:/var/lib/postgresql/data posgres:17-alpine

컨테이너에 볼륨을 장착하려면 컨테이너 띄울 때 -v 명령어 쓰면 된다.
-e로 환경변수 집어넣는건 알아서 해보자.
그리고 컨테이너 안에 있는 어떤 폴더를 볼륨에 복사해둘건지 경로도 맘대로 정하면 된다.

PostgreSQL의 경우 /var/lib/postgresql/data 이런 폴더에 DB데이터를 저장해두기 때문에
그걸 볼륨에 복사하라고 하면 된다.

MySQL을 쓰는 경우 /var/lib/mysql 이런 폴더에 DB 데이터를 저장해두기 때문에
그걸 볼륨에 복사하라고 하면 된다.

이런건 DBMS 종류마다 다르기 때문에 찾아서 쓰자.

* 볼륨에 데이터 저장되나 확인해보자

DB데이터가 진짜로 볼륨에 복사되나 확인해보자.
그러기 위해서 DB 컨테이너 접속해서 테이블에 데이터 몇개 집어넣어보자.

방금띄운 컨테이너 터미널에 접속하고
psql -U admin -W 이걸로 psql 켠다음에 

\l 해서 데이터베이스 목록 조회해보고 
\c postgres 이걸로 써서 아무 데이터베이스나 들어가보고

이제 여기다가 SQL 문법을 좀 짜서 테이블을 생성하고 거기다가 데이터도 하나 넣어보자.

CREATE TABLE product ( title VARCHAR(100) );
INSERT INTO product VALUES ('shirt');
SELECT * FROM product;

차례로 테이블 만들기, 테이블에 행 집어넣기, 테이블 출력하기 SQL 문법이다.

▲ 지금 DB에 만든걸 그림으로 보자면 이런 식으로 데이터를 하나 저장해봤는데
볼륨을 장착했을 경우 이 데이터가 볼륨에도 복사된다.

이제 컨테이너를 아예 삭제했다가 다시 띄워도 같은 볼륨만 잘 장착하면 데이터를 다시 불러올 수 있는데
남의 말 믿지 말고 진짠지 확인하려면
직접 컨테이너 지웠다가 다시 볼륨넣어서 띄워보시면 된다.

그 다음에 데이터 그대로 남아있는지 psql로 데이터베이스와 테이블 접속해서 SQL 문법으로 출력도 해보자.

* bind mount

볼륨은 docker에서 관리해주는 폴더같은 개념이다.
docker가 관리해주는게 싫으면 여러분이 컴퓨터에 만들어둔 폴더를 볼륨으로 장착할 수도 있다.

어떻게 하냐면 volume 만들 때 여러분 로컬 폴더 경로 집어넣어주면 된다.

docker run -v /내컴퓨터폴더경로:/컨테이너경로 이미지명

이러면 내 폴더에 있던 데이터들을 볼륨으로 장착해준다.

이걸 bind mount라고 부른다.

내가 이 데이터를 주기적으로 백업해야되는 경우에는 bind mount 방식으로 쓰는게 나중에 데이터 찾을 때 편리할 수도 있긴 하다.

하지만 실제 백업을 해야된다면 직접 손으로 하는 것 보다는
볼륨을 장착해서 거기 내용을 압축해서 AWS이런데 업로드하는 별도의 이미지를 만들어서 실행해놓아도 되긴 하다.

아니면 그런 백업 역할의 이미지를 누가 이미 만들어둔 것도 많고
그런거 실행만 해두면 알아서 주기적으로 볼륨을 가져와서 AWS이런데 백업해주니까 그런거 돌려도 된다.

https://github.com/offen/docker-volume-backup

* 오늘의 결론:
컨테이너 데이터를 영구적으로 보존해야된다면 볼륨을 만들어서 장착해보자.

그럼 컨테이너 데이터는 볼륨에 자동으로 복사되고
나중에 컨테이너 띄울 때 볼륨에 있던 내용을 컨테이너에 집어넣어서 띄울 수도 있다.

그래서 데이터베이스 컨테이너 띄울 때 유용한데
하지만 컨테이너는 쉽게 띄우고, 쉽게 교체하고, 다른 곳으로 옮기고 이런게 장점인데
데이터베이스는 그런 것 보다 안정성이 중요해서
실은 데이터베이스는 컨테이너로 만들어서 띄우는 경우가 많지는 않다.

따로 데이터베이스 호스팅을 받아서 거기서 안전하게 데이터들을 관리하는게 나을 수 있다.

참고로 서버에서 PostgreSQL에 접속해서 이거저거 SQL 실행하려면 

1. 터미널에서 npm install pg 입력해서 라이브러리 설치하고

2. 아래 코드 서버에 작성해놓고
const { Pool } = require('pg');
const pool = new Pool({
  host: 'db', //DB컨테이너이름
  database: 'postgres', //접속할Database이름
  user: 'admin', //유저이름
  password: 'qwer1234', //비번
  port: 5432,
});

3. SQL 실행이 필요할 때 마다 아래처럼 pool.query() 쓰면 된다.
app.get('/add', async (req, res) => {
  try {
    await pool.query(`CREATE TABLE IF NOT EXISTS products (
      id SERIAL PRIMARY KEY,
      title VARCHAR(255),
      price INT
    );`);
    res.send('SQL 실행 완료')
  }
  catch (err) {
    console.log(err)
    res.send('실패')
  }
});

(예) 서버에서 MySQL에 접속해서 이거저거 SQL 실행
참고 - PWS 솔루션 -> 파일 경로 "C:\Users\bhjeon\Downloads\PWS소스_상상진화_20240910\pws-server\lib" 폴더 -> "pwsdb-dao.js" 파일 

11강 - Docker compose 1. 서비스 작성하기

* Docker compose 사용 전 필수 사항
- 비쥬얼스튜디오코드(VSCode) 사용시 확장 프로그램 "Docker" 설치 필수 

docker run 명령어가 슬슬 길어지면 docker를 버리고 싶어진다.
그게 싫으면 명령어들을 한 파일에 입력해놓고 그걸 실행하는 식으로 코드짜놓아도 된다.

그럴려면 shell script 이런거 짜서 실행해도 되긴 하는데
docker compose 라는 프로그램을 쓰면 훨씬 쉽게 구현가능하다.

따로 설치할 필요는 없고 docker desktop 설치할 때 같이 설치된다.

* docker compose 사용하는 법

1. docker-compose.yml 파일 하나 만들어서
2. 거기다가 docker run 어쩌구 쓰던 명령어들을 쭉 나열하고
3. 이제 터미널에서 docker compose up 이라고 입력하면 이 파일(docker-compose.yml)에 있던 내용이 쭉 실행된다.

편리하죠?
하지만 docker compose 문법 + yaml 파일형식에 맞게 .yml 파일을 채워야 한다.

* services

.yml 파일이 뭐냐면 일단 데이터 저장하는 용도의 파일형식이다.
.json 아는 분들은 그 파일이랑 비슷한 것이라고 생각하면 된다.
.yml 파일은 데이터이름 : 값 이런 식으로 저장한다.

어떤 데이터에 속하는 하위 데이터는 인덴트 넣고 데이터이름 : 값 적으면 끝이다.
(예) (docker-compose.yml)
services:
  컨테이너이름:
    image: 이미지이름
    ports: 
      - 내컴퓨터포트:컨테이너포트

그래서 아무데나 docker-compose.yml 파일 만들어서 이렇게 작성해보자. 
services: 라고 적고 인덴트 넣어서 하위 항목으로 컨테이너 이름을 하나 작명하자.
정확히는 서비스 이름인데 일단은 컨테이너 이름이라고 부르자.

그 다음에 하위 항목으로
image: 이미지이름 적으면 이 이미지를 컨테이너로 띄워준다.
ports: 하위항목으로 포트바인딩 어떻게 할 건지도 정할 수 있다.

- VSCode 에디터 쓰는 분들은 이런거 작성할 때 Docker 부가기능 설치하면 편리할 수 있다.
- 참고로 예전엔 도커 version 부터 맨 위에 넣고 시작했는데 요즘은 그럴 필요 없다.

* 환경변수 넣으려면
(예1) (docker-compose.yml)
services:
  컨테이너이름:
    image: 이미지이름
    ports: 
      - 내컴퓨터포트:컨테이너포트
    environment:
      - 환경변수이름=값
      - 환경변수이름=값

환경 변수는 이런식으로 하나하나 적어두면 된다.
하나하나 적기 귀찮으면 다른 파일에 있는걸 끌어다가 쓸 수 있다.

(예2) (.env)

POSTGRES_USER=admin

예를 들어 우리가 코딩할 때 .env파일에 환경변수를 가끔 적어놓기도 한다.
이 파일에 있는걸 docker compose 설정파일에서 그대로 가져올 수도 있다.

(예3) (docker-compose.yml)
  environment:
    - POSTGRES_USER: ${POSTGRES_USER}

그럴려면 ${} 쓰고 .env 파일에 있는 환경변수 이름 적어주면 된다.
.env 파일이 여러개 있으면 그 중에 어디서 가져올건지 명시하는 기능도 있는데 필요할 때 찾아쓰자.

* 띄우는 명령어는

(예) (docker-compose.yml)

services:
  webserver:
    image: nodeserver:1
    ports: 
      - 8080:8080

그래서 전에 만들어 놓은 웹서버 띄우고 싶어서 이렇게 작성해놨다.

docker compose up -d   # 컨테이너 띄우기
docker compose stop    # 컨테이너 정지
docker compose down    # 컨테이너 삭제

docker compose 파일을 기반으로 컨테이너를 띄우고, 정지하고, 삭제하려면 차례로 이런걸 입력하자.

* 다른 컨테이너 띄우기

웹서버는 잘 뜨는 것 같은데
nginx같은 다른 컨테이너를 하나 더 띄우고 싶으면 
service: 하위 항목을 더 정의하면 된다.
그니까 띄울 이미지마다 서비스 하나씩 만들면 된다고 생각하면 된다.

(예) (docker-compose.yml)

services:
  webserver:
    image: nodeserver:1
    ports: 
      - 8080:8080

  nginx:
    image: nginx:1
    ports: 
      - 80:80

그래서 저장하고 docker compose down 한 다음에 docker compose up -d 해보면
컨테이너 2개가 동시에 잘 뜬다.

* 네트워크

컨테이너간 통신이 필요해서 네트워크가 필요하다면
실은 네트워크를 따로 만들고 그럴 필요가 없다.

services: 하위항목에 있는 컨테이너들은
자동으로 네트워크 하나 만들어서 거기 전부 넣어주기 때문에 그렇다.

그리고 네트워크 안에 있는 컨테이너끼리 서로 찾으려면
IP주소 혹은 컨테이너 이름 (서비스 이름)을 기재하면 되니까 알아서 nginx와 웹서버 연결 해보면 된다.


* 여러 컨테이너들이 서로 dependency가 있으면?

컨테이너들을 띄우다보면
어떤 컨테이너는 다른 컨테이너가 떠있어야 제대로 동작하는 경우가 있다.

(예) nginx => webserver => DB

예를 들어 nginx는 "웹서버에 보내주세요~"
웹서버는 "DB에 연결해주세요~"
이런 식으로 코드가 짜여져있는게 일반적이다.

이런 경우에는 DB먼저 띄우고 웹서버 띄우고 그 다음에 nginx 띄우면 좀 안정적이지 않겠습니까.
그리고 그래야 잘 돌아갈 것 같다.

(예) (docker-compose.yml)

services:
  webserver:
    image: nodeserver:1
    ports: 
      - 8080:8080

  nginx:
    image: nginx:1
    ports: 
      - 80:80
    depends_on:
      - webserver

depends_on: 하위 항목으로 다른 서비스 이름을 기재할 수 있는데
그러면 위의 코드에선 nginx는 webserver에 의존한다는 뜻이다.

그럼 webserver 컨테이너가 먼저 실행된 다음 nginx 컨테이너가 실행된다.
그래서 컨테이너 실행 순서를 결정하고 싶으면 depends_on: 을 사용해보자.

* 서비스 
docker compose에선 컨테이너를 "서비스" 안에 작성하는데
서비스가 뭐냐면 컨테이너를 어떻게 띄울지 정의하는 일종의 가이드같은 개념이다.

(예) (docker-compose.yml)

services:
  webserver:
    image: nodeserver:1
    ports: 
      - 8080:8080

이미지가 있으면

- 어떤 포트를 열지
- 어떤 환경변수를 넣을지
- 컨테이너 이름은 어떻게 지을지

이런걸 결정해야 이미지를 컨테이너로 실행할 수 있지 않습니까
이런 컨테이너 실행 가이드를 docker compose에서 서비스라고 부른다.

서비스라는 개념이 중요한데
왜냐면 여러분이 나중에 컨테이너 수백개를 띄우게 되면 그걸 관리하기 위한 프로그램을 따로 사용한다. 

Docker swarm, Kubernetes, AWS ECS 이런게 있는데
이런걸 써도 항상 서비스와 비슷한 걸 작성한 뒤에 컨테이너들을 띄우게 된다.
그래서 잘 기억해두자.

서비스를 만들어두면 장점이 뭐냐면
컨테이너 설정을 한 눈에 볼 수 있는 것도 있는데
나중에 같은 컨테이너 여러개가 필요할 때도 편리해진다.

"서비스에 써있는 내용대로 컨테이너 여러개 복사해서 띄워주세요" 이런게 가능해진다.

(예) (docker-compose.yml)

services:
  webserver:
    image: nodeserver:1
    ports: 
      - 8080:8080
    deploy:
      mode: replicated
      replicas: 3

심심하니까 진짜로 해보면 
서비스마다 deploy: 옵션을 넣으면 같은 컨테이너를 동일한 설정으로 여러개 복제해서 띄울 수 있다.
복제해서 실행하려면 docker compose --compatibility up 이런 명령어 쓰면 된다.

12강 - Docker compose 2. network, volume

간단한거 띄울 때도 쓸데없는 docker 명령어들 길게 입력하는 것 보다
docker compose 파일에 기록해놓고 실행하는게 훨씬 편해서 앞으로 자주 쓰게 될텐데
그래서 docker compose 사용예시를 좀만 더 알아보도록 하자.

* 직접 network 만들기

원래 services: 안에 있는 모든 컨테이너들은 자동으로 네트워크 하나 안에 담아준다.
그래서 네트워크 따로 설정하고 그럴 필요는 없는데
간혹 네트워크를 여러개 만들어서 컨테이너를 안전하게 배치하고 싶을 때도 있다.

예를 들어 nginx, 웹서버(webserver), DB가 있으면
nginx <-> 웹서버(webserver)는 서로 통신해야하고
웹서버(webserver) <-> DB는 서로 통신해야하고
근데 nginx <-> DB는 서로 통신할 일이 아마 없다.

그래서 각각 통신이 필요한 컨테이너끼리 하나의 네트워크에 보관하는 것도 안전하고 좋을 수 있다.
(하나의 컨테이너는 여러개 네트워크에 속할 수 있다.)
(예) 웹서버(webserver)
nginx <-> 웹서버(webserver) <-> DB

네트워크 mynet1: nginx <-> 웹서버(webserver)
네트워크 mynet2: 웹서버(webserver) <-> DB

services:
  webserver:
    image: nodeserver:1
    ports:
      - 8080:8080
    networks:
      - mynet1
      - mynet2

  nginx:
    image: nginx:1
    ports:
      - 80:80
    networks:
      - mynet1

  db:
    image: postgres:17-alpine
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=qwer1234
    networks:
      - mynet2

networks:
  mynet1:
  mynet2: 

그래서 위처럼 구현해봤다.
networks: 라는 최상위 항목을 하나 만들어서 안에 네트워크 이름(mynet1:, mynet2:)을 넣으면 그 이름으로 네트워크를 만들어준다.
위 예시에선 mynet1, mynet2 네트워크를 만들었다.

그럼 이제 서비스마다 networks: 넣어서 네트워크안에 컨테이너(webserver:, nginx:, db:)를 넣을 수 있다.

* volume 사용하기

docker compose 파일 사용할 때도 볼륨 장착하라고 명령가능하다.

services:

  db:
    image: postgres:17-alpine
    environment:
      - POSTGRES_USER=admin 
      - POSTGRES_PASSWORD=qwer1234
    volumes:
      - 볼륨이름:/var/lib/postgresql/data

volumes:
  기존 볼륨이름:
    external: true

volume: 쓰고 그 안에 볼륨장착하는 명령어 입력하면 된다.
하지만 그냥 쓰면 docker compose 실행시 직접 볼륨을 새로 만들어주기 때문에
그게 싫고 기존에 있던 볼륨을 쓸려면 최상단에 volumes: 넣고 기존 볼륨이름과 external: true를 넣어줘야한다.

참고로 개발자가 만든 폴더를 volume으로 쓰기 위해 
bind mount 식으로 볼륨을 쓰려면 볼륨이름 대신 여러분들 폴더경로를 적어주면 된다.
예를 들어 docker compose 파일과 같은 경로에 vol 폴더를 볼륨으로 쓰려면
볼륨이름란에 ./vol 이렇게 적는게 어떨까요.

* 기타 명령어들

가끔가다가 프로그램이 혼자 종료되는 상황들이 있다.
웹서버의 경우엔 유저가 너무 많거나 이상한 코드가 있거나 그러면 프로그램이 종료될 수 있다.

그럴 땐 어떻게 하게요?
꺼지면 자동으로 다시 실행하라고 코드를 짜두거나 그럴 수 있다.

- nodejs같은 경우엔 pm2같은 라이브러리 쓰면 다운되거나 그럴 때 그냥 알아서 다시 시작해준다. 
- nginx같은 경우엔 리눅스의 systemctl 같은 프로그램 쓰면 더 간단하고 편할 수 있다.

하지만 docker를 쓰는 경우 알아서 재시작해주는 간편한 옵션이 있다.

services:
  (생략)
  nginx:
    image: nginx:1
    ports:
      - 80:80
    restart: always

restart: always 이런거 넣어두면 컨테이너가 꺼져도 알아서 재시작된다.
심지어 docker 엔진 자체가 껐다 켜져도 알아서 서비스가 자동으로 시작된다.

그래서 항상 재시작되어야하는 프로그램이 있으면 이거 적어두자.
참고로 docker compose 안쓸거면 docker run -d --restart always 이런 식으로 옵션을 집어넣자.

엄마가 남의 말 믿지 말랬으니 진짜인지 확인하려면 docker desktop 껐다 켜보셔도 되고
아니면 컨테이너를 오류발생시켜서 끄고 싶으면 nginx같은거에 docker exec으로 접속해서 kill 명령한번 줘보면 된다.

▲ docker desktop 응용 프로그램 -> 컨테이너 "docker-nginx-1" 실행 -> 해당 컨테이너 들어가서 리본 버튼 "Exec" 클릭
  "Exec" 터미널에 ps 입력하면 현재 실행중인 프로세스들을 볼 수 있는데
잘보면 1번 프로세스로 nginx 명령어가 실행중이다. (예) nginx -g daemon off;

이걸 강제종료 해버리고 싶으면 터미널에 kill 1 입력하면 된다.
근데 restart always를 적어놨기 때문에 종료되어도 해당 컨테이너("docker-nginx-1")가 알아서 재시작되는걸 볼 수 있다.
(재시작 되었는지 모르겠으면 컨테이너의 Inspect 메뉴에서 restart 어쩌구 검색해보자.)

참고로 여러분들이 docker 명령어나 이런걸로 컨테이너를 직접 정지시켰을 때는
restart를 뭘로 해놨든 간에 자동 재시작은 안된다.

services:
  (생략)
  nginx:
    image: nginx:1
    ports:
      - 80:80
    restart: unless-stopped
restart: unless-stopped 이런 명령도 비슷한데 얘는 docker 재시작해도 자동으로 시작은 안된다.
실은 비슷해서 그냥 이거 쓰도록 하자.

13강 - Docker compose 3. 실시간 개발, graceful shutdown

가끔 개발할 때 컨테이너로 띄워보면서 개발해보는 경우들이 있다.

- 팀원끼리 개발환경 아예 똑같이 맞출 때
- 배포전에 테스트하려고
- 그냥 편해서

이런 이유로 컨테이너로 미리보기 띄워서 개발하는 경우들이 있다.

하지만 이러면 귀찮은 점이 있는데
예를 들어 서버에서 "안녕"이라는 메세지를 "안녕123" 이런 식으로 바꿨다.
이 변동사항이 컨테이너에서도 잘 돌아가는지 확인하려면 어떻게 하게요?

1. docker compose down 하고
2. 웹서버 이미지 다시 만들고
3. docker compose up 해야한다.

이러면 귀찮아서 도커 삭제하고 싶어질텐데 당연히 개선 방법이 몇개 있다.

* 빌드 자동화

가장 간단한 해결책은
docker compose 파일(docker-compose.yml)에 "항상 docker build 하고 나서 컨테이너 띄우세요" 이렇게 설정하면 된다.

(예) docker compose 파일(docker-compose.yml)
services:
  webserver:
    image: nodeserver:1
    build: .
    ports:
      - 8080:8080

build: 도커파일경로 입력하면 되는데
그럼 이제 docker compose up 할 때마다
해당 경로에 있는 도커파일(Dockerfile)을 가져다가 자동으로 docker build 명령을 수행해서 이미지를 생성하고
그 이미지로 컨테이너를 띄워준다.

하지만 docker compose up 말고
docker compose up --build
이런 명령어를 써야 자동으로 docker build 명령을 수행해준다.

그럼 아까와 다르게
1. docker compose down 
2. docker compose up --build

입력하면 되니까 명령어가 1개 줄어들어서 편리해졌군요.

* graceful shutdown 기능

컨테이너 끄고 재시작하고 그런게 너무 느린경우들이 있다.
특히 웹서버하나 끄는데 10초넘게 걸린다면 그 이유는 서버 꺼주는 코드를 안짜서 그런 것일 뿐이다.

▲ 원래 docker 엔진이 컨테이너를 종료시킬 때 무슨 일이 일어나냐면
"좋은말할 때 알아서 끄라" 이런 식으로 메세지를 컨테이너의 프로그램으로 보낸다.
그래서 프로그램은 그 경고성 메세지를 수신하면 알아서 종료하라고 코드짜놓으면 된다.
근데 종료하는 코드가 없거나 그러면 10초 정도 기다렸다가 강제로 꺼진다.
그래서 종료하는 코드를 좀 작성해보도록 하자.

(예) (server.js)
const server = app.listen(어쩌구) 

process.on('SIGTERM', () => {
  server.close(() => {
    console.log('HTTP server closed')
  })
})
process.on('SIGINT', () => {
  server.close(() => {
    console.log('HTTP server closed')
  })
}) 

그래서 웹서버에 SIGTERM 메세지가 들어오면 server.close()하라고 코드짰다.

- express의 기본 기능인 server.close() 를 사용하면 서버에 들어온 요청을 다 처리한 후에 이쁘게 알아서 꺼진다.
- SIGTERM은 Docker 엔진이 컨테이너 종료할 때 보내는 "좋은 말할 때 알아서 끄라" 경고메세지이다.
- SIGINT는 유저가 터미널에서 ctrl + c 누를 때 보내지는 메세지이다.
- 참고로 터미널에 kill 1 입력하는 것도 SIGTERM 메세지 보내는 것이다.

근데 나중에 서버에서 DB도 쓰고 그러면 서버를 끌 때 DB 연결 해제하는 것도 좋다.
이런 식으로 끄기 전에 이거저거 챙기는걸 멋있는 말로 graceful shutdown 이라고 한다.

그래서 컨테이너로 돌릴 프로그램들은 자주 껐다켜지고 그럴 수 있으니까
컨테이너 안의 프로그램들에 graceful shutdown 잘해놨나 확인하는 것도 좋은 습관이니까 나중에 한번 챙겨보자.

* watch 기능

아까 "실행하기 전에 자동으로 빌드하세요" 이렇게 해놨는데 이것도 쓰다보면 오래걸려서 도커 삭제하고 싶어지는데
그럴 땐 시간내서 docker compose의 watch 기능 셋팅해두면
특정 파일이 변경될 때마다 얘가 바로바로 컨테이너에 복사를 해주기 때문에
그래서 이거 쓰면 매번 빌드 그딴거 할 필요가 없어서 매우 편리해진다. 나름 최신기능임

(예) docker compose 파일(docker-compose.yml)
services:
  webserver:
    build: .
    ports:
    - 8080:8080

    develop:
      watch:
        - action: sync
          path: .
          target: /app
          ignore:
            - node_modules/
        - action: rebuild
          path: package.json 

우선 이런 식으로 작성해두자.
실시간 반영원하는 컨테이너에 develop: 넣고
watch: 넣고 시작하면 된다.

1. - action: sync 는 내 컴퓨터에 있던 파일 변경사항을 컨테이너로 복사해주라는 뜻이다.
복붙말고 빌드, 컨테이너 재시작 등 다른 행위도 할 수 있는데 그건 나중에 확인해보자.
2. path: 에는 내 컴퓨터의 어떤 파일들 감시할건지 경로 적으면 된다.
3. target: 에는 컨테이너 어디에 변동사항을 복사할건지 경로 적으면 된다.
4. ignore: 안에는 변동사항을 복사할 필요가 없는 파일이나 폴더("node_modules")들 기록해두면 되는데 .dockerignore 파일 쓰고 있으면 따로 적을 필요는 없다.

그래서 위처럼 적으면 현재 폴더에 있는 파일들이 변동사항이 생겼을 때 app 폴더 안에 그대로 변동사항이 복사된다.

(참고) build: 옵션이 들어있어야 잘된다.

진짠지 테스트
테스트해보려면 docker compose down 했다가 다시 up 하면 될텐데
실은 docker compose up --watch 라고 명령을 줘야 watch 기능이 동작한다. 
이렇게 해두면 이제 코드 변경할 때마다 빌드하고 지랄할 필요가 없어진다.

▲ 진짜 그런지 코드 수정하고 저장해봤는데
그러면 docker desktop 들어가서 컨테이너 들어가서 파일(server.js) 검사해보면 소스코드가 진짜로 컨테이너에 실시간으로 복사된걸 볼 수 있다.

근데 브라우저 열어서 서버에 접속해보면.. 업데이트가 안되고있는데요?
왜 그러냐면 원래 로컬에서 개발할 때도 코드 수정했으면 서버를 재시작해줘야 반영이 된다.
그래서 그럴 뿐이라 서버도 재시작하라고 설정을 바꾸면 된다.

(예) docker compose 파일(docker-compose.yml)
services:
  webserver:
    build: .
    ports:
    - 8080:8080

    develop:
      watch:
        - action: sync+restart
          path: .
        (생략)

- action: sync+restart 이런 옵션을 넣으면 sync한 후에 컨테이너 재시작하라는 뜻이다.
진짜 재시작까지 잘 되나 테스트해보자.

보통 nginx같은것도 설정을 바꾸면 한번 재시작해야 적용이 되기 때문에 
코드 바꿀 때 마다 재시작이 필요한 컨테이너에 달아놓으면 개발할 때 편리하다.

* command로 CMD 덮어쓰기

참고로 nodejs로 서버개발하는 경우에는 
nodemon같은 라이브러리를 설치해서 nodemon server.js라는 명령어로 서버를 띄우면
파일변경이 생길 때마다 재시작을 알아서 해줘서 이런거 써도 된다.

그래서 명령어를 node server.js에서 nodemon server.js로 바꾸면 될텐데
Dockerfile가서 마지막 CMD 명령어를 수정하고 그런게 귀찮으면
docker compose 파일(docker-compose.yml)에서 CMD 명령어를 덮어쓸 수 있다.

(예) docker compose 파일(docker-compose.yml)
services:
  webserver:
    build: .
    ports:
    - 8080:8080

    command: ["nodemon", "server.js"]
    develop:
        (생략)

command: 이런걸 서비스마다 넣을 수 있는데
그러면 그 서비스를 띄울 때 dockerfile에 있던 CMD 옆에 있는 명령어를 덮어쓰기할 수 있다.
그래서 docker compose 실행시 매번 다른 명령어 넣을 수 있으니까 필요할 때 사용하자.

* action: rebuild

(예) docker compose 파일(docker-compose.yml)
services:
  webserver:
    build: .
    ports:
    - 8080:8080

    develop:
      watch:
        - action: rebuild
          path: package.json
        (생략)

- action: rebuild 집어넣으면 
path에 있는 파일이나 폴더가 변동사항이 생기면 그냥 아예 docker build를 다시 해달라는 뜻이다.
이미지 다시 만들라는 뜻임

그래서 Node.js 개발하는 경우에는 라이브러리같은거 설치하는거 변동사항이 생기면
이미지를 다시만드는게 깔끔하기 때문에 package.json파일 변경되면 rebuild하라고 코드짜놓는 경우들이 있다.

코드수정하고나서 항상 컴파일이 필요한 프로젝트들도 이걸 sync가 아니라 rebuild로 적는 경우들이 있다.

- action: 은 여러개 집어넣을 수 있으니 필요하면 사용하자.

오늘의 결론:
내 코드를 컨테이너로 띄워보면서 실시간 코딩하고 싶으면 docker compose의 watch 기능을 꺼내쓰자.
컨테이너 껐다가 켤 일이 많다면 graceful shutdown 잘해놨나 확인하자.     

14강 - Orchestration 1. 태스크, 서비스, 클러스터 개념정리

배포같은거 어떻게 하냐고 물어보시는데
이미 여러분들 컴퓨터에서 서버가 잘 돌아가고 있기 때문에
다른 사람들이 "내아이피주소:8080"으로 들어가면 여러분들 서버를 만날 수 있다.

근데 컴퓨터를 24시간 켜두기도 그렇고 집컴퓨터는 IP주소도 자주 바뀌기 때문에
AWS 이런 곳에서 컴퓨터를 빌려서 거기에 서버를 띄워놓는게 안정적이다.

그래서 1. 환경셋팅하고 2. 코드짜거나 거기로 옮기고 3. 실행하고 그런 작업을
AWS에서 컴퓨터를 하나 빌려서 동일하게 하면 배포 끝이다.

하지만 직접 하는건 매우 귀찮기 때문에
- 내 코드를 이미지로 만들어서 어디 올리고
- 이미지를 AWS 컴퓨터에서 다운받고
- AWS 컴퓨터에 도커같은거 설치해서 이미지를 실행해두는게 끝임 

* 마이크로서비스 등장

이미지로 배포하면 배포과정이 매우 쉬워진다.
이미지 다운 받아서 실행누르면 끝이니까요.
근데 몸이 편해지면 사람들이 슬슬 이상한 짓을 하기 시작한다.

(예) 마이크로서비스 아키텍처(MicroService Architecture)
- 회원기능
- 결제기능
- 쇼핑기능
- 댓글기능 

서버의 여러 기능들을 하나의 프로그램에 넣는게 아니라
기능을 분리해서 각각 별도의 프로그램으로 만들고 각각 개별적인 컨테이너로 띄워둔다.

그리고 컨테이너들은 필요할 때만 서로 통신하도록 설정한다.
이런 방식을 마이크로서비스 아키텍처(MicroService Architecture)라고 부른다.

그러다보니 컨테이너 수가 많아지고
이걸 관리하기 위해서 container orchestration 툴을 사용하는 경우가 늘어나고 있다.

그래서 우리도 그걸 맛보도록 하자.
솔직히 컨테이너가 몇 개 없을 때는 별로 필요없는데
내 몸값에 거품을 만들고 싶다면 남들이 어려워하는 기술을 일부러라도 써보는게 좋다.

* 컨테이너 orchestration tool

orchestration 툴은 쿠버네티스가 가장 유명하다.
직접 여러분이 컴퓨터에 설치해서 운영하고 그래도 되긴 하는데
사이즈가 커지면 관리형 쿠버네티스 서비스를 쓰는 경우들이 많다.

▲ 이런 상품들이 있는데 직접 셋팅하는 것 보다 편하게 쿠버네티스를 사용할 수 있다.
근데 이런 것도 입문하려면 새로 배울게 좀 많기 때문에
훨씬 쉽고 간단한데 기능은 비슷한 ECS를 써서 입문해보도록 하자. 
AWS에서 만든 orchestration 툴이다.

* 실은 저런거 안써도 세상이 좋아짐

아니면 서버를 만들고 있다면 그걸 더 쉽게 배포할 수 있는 방법이 요즘은 많다.

- 이미지나 코드를 쉽게 배포해주는 상품 (Google cloud app engine, Google cloud run, AWS Elastic beanstalk)
- 쿠버네티스를 쓰고 싶은데 관리하기 싫으면 쓰는 상품 (GKE autopilot)
- AWS ECS를 쓰는데 명령어 한두개만으로 ECS에 배포해주는 툴 (AWS Copilot)
- 아니면 배포를 더 쉽게 만들어주는 Fly.io, Heroku, Vercel같은 서비스도 나와있다. 다만 한국 리전은 없는 경우도 있음

참고로 Fly.io 같은 서비스는 이미지를 올리면 이미지를 해체해서 Firecracker같은 VM에 올려서 서비스한다.
왜냐면 컨테이너들은 같은 커널을 공유하기 때문에 보안이슈가 있을 수 있는데
그걸 원천차단하기 위해서 컨테이너말고 가벼운 VM을 쓰는 건데 그럴 수도 있다는걸 참고하자.

* 서버를 만들었다고 가정해보자

실제 상황부터 한번 가정해보자.
마이크로서비스가 좋다니까 여러분이 1. 회원서버 2. 게시판서버를 개발해놓은것이다.

이 마이크로서비스들을 배포하고 싶으면 어떻게 하냐면
컴퓨터 2개 빌려서 각각 띄워둬도 되는데 우리는 AWS에 있는 ECS를 써볼것이다.
그걸 쓰면 어떤 식으로 하냐면...

▲ 클러스터안에 서비스 안에 태스크 안에 컨테이너들을 띄운다.
클러스터(Cluster) > 서비스(Service) > 태스크(Task)

- 클러스터(Cluster)는 하나의 프로젝트
- 서비스(Service)는 하나의 마이크로서비스
- 태스크(Task)는 서로 붙어있어야할 컨테이너들을 묶는 단위이다.

그래서 지금 우리는 마이크로서비스가 2개 있으니까 서비스(Service)를 2개 만들고
서비스(Service)마다 필요한 nginx, 웹서버, DB 이미지들을 태스크(Task) 안에 감싸서 띄우면 되는것이다.

태스크(Task)는 비유하자면 그냥 docker compose와 비슷한거라고 생각하면 된다.
참고로 태스크(Task)는 원하는 만큼 복제가 매우 쉽다.

▲ 클러스터(Cluster)를 만들 때 컴퓨터를 몇대 빌릴지 예약할 수 있다.
그래서 빌린 컴퓨터마다 태스크(Task)들을 퍼트려놓는 것도 가능하다.
그럼 컴퓨터 하나가 맛이가도 안전하겠군요.

그리고 볼륨장착, 컨테이너간 통신, 서비스간 통신 이런 것도 당연히 가능하다.

▲ 근데 생각해보면 서비스(Service)라는 부분은 필요없을 것 같지 않습니까?
실은 그렇긴 하다. 
그래서 서비스(Service) 생략하고 태스크(Task)만 띄울 수도 있긴 한데

서비스(Service)가 있으면

- 태스크(Task)를 쉽게 복제해주고
- 고장난 태스크(Task)는 새걸로 갈아치워주고
- 다른 서비스(Service)끼리 통신하고

이런게 쉬워져서 사용하는 레이어라고 보면 된다.

참고로 쿠버네티스도 이거랑 비슷하게 동작하는데 직접 컨트롤할 수 있는게 더 많을 뿐이다.

* 치킨집으로 비유하자면

비유좋아하면 간단하게 치킨집으로 비유좀 해보자.
내가 치킨 밀키트를 만들었는데 그걸 고객들에게 맛을 보여주고 싶으면 어떻게 하겠습니까.

클러스터(Cluster) > 치킨집/피자집 가맹본부(Service) > 치킨집 체인점 1/2/3 or 피자집 체인점 1/2/3 (Task)

▲ 치킨집 가맹본부 만들고 체인점을 만들고 그 안에서 치킨 밀키트를 조리하면 된다.
이번엔 피자 밀키트를 만들었으면
피자집 가맹본부 만들고 체인점을 만들고 그 안에서 피자 밀키트를 조리하면 된다.

가맹본부(Service)에선

- 체인점(Task)을 여러개 띄우고
- 필요없는 체인점(Task)은 줄이고
- 가맹본부(Service)끼리 콜라보하고

그런 행위가 가능하다.

* load balancer

근데 이런거 쓰다보면 자주 필요한게 하나 있다.
로드밸런서(load balancer)라는 것인데 잠깐 설명하고 지나가자.

위에서 설명한 환경에선 서버를 복제해두고 싶으면 태스크(Task)를 복제해두면 된다.
근데 그러면 유저가 서버로 접속하고 싶을 때 대체 몇번째 태스크(Task)로 접속해야하는지 모르지 않습니까.

그럴 때 로드밸런서(load balancer)를 앞에 붙일 수 있다.

로드밸런서(load balancer)는 그냥 간단한 프로그램인데
유저가 나한테 들어왔을 때 내 뒤에 있는 컴퓨터나 태스크(Task)들에 균등하게 안내해주는 역할을 하는 프로그램이다.

참고로 nginx도 "누가 나에게 들어오면 뒤에 있는 여러 웹서버 중에 하나로 안내해주세요" 라고 코드짜놓을 수 있어서 로드밸런서(load balancer)같은 짓을 할 수 있다.

특히 컨테이너들이 서버리스 형태로 자원을 사용하는 경우에도 로드밸런서(load balancer)가 필요하게 될텐데
그래서 로드밸런서(load balancer) 프로그램을 하나 만들어두고
아무나 접속가능하게 만들고

누가 로드밸런서(load balancer)에 들어오면 서비스(Service)나 태스크(Task)를 가리키게 하면 이제 유저가 서버들로 접속할 수 있게 된다.
그래서 그것도 나중에 하나 만들어보자.

* 장단점 

마이크로 서비스 형식으로 설계를 해두면 장점이 뭘까요.

- 유저가 많이 몰리는 그런 서비스(Service)가 있으면 그것만 딱 찝어서 CPU 사용량 늘리고 그럴 수 있어서 자원 사용이 효율적임
- 회원기능을 수정했으면 회원기능 서비스(Service)만 따로 배포하면 되니까 기능 업데이트도 매우 빨라짐

그래서 이딴 짓을 하는 것이다.

단점은 뭐게요?

- 마이크로 서비스끼리 통신해야하면 그게 좀 귀찮아짐
- 마이크로 서비스가 많아지면 그걸 관리하는데 시간과 인력이 추가로 필요함
- 서버비도 초반엔 비쌈

그래서 처음부터 모든걸 마이크로 서비스로 만드는 것 보다는
기존처럼 한 프로그램에 모든걸 넣어서 개발하다가 기능이 너무 크고 비대해지는 부분이 있으면
그걸 마이크로 서비스로 슬쩍 빼보면서 시작하는게 좋은 관습이다.

* 실제로 올려보기 전에 셋팅할게 있음 
주의사항 - AWS ECS(Amazon Elastic Container Service)에 DB(postgres 등등...) 띄워 보면(올려 보면) 나중에 태스크(Task)를 여러 개 복제해두면 
          DB(postgres 등등...) 또한 여러개 복제될텐데 이상해질 수 있다.
          예를들어 태스크(Task) A의 DB(postgres 등등...)에 존재하는 데이터 테이블에 속한 데이터 로우에 특정 컬럼 값을 변경하면 
          (예) (기존) user: '1', name: 'kim' -> (변경) user: '1', name: 'park'
          다른 태스크(Task) B의 DB(postgres 등등...)에 존재하는 데이터 테이블에 속한 데이터 로우 또한 특정 컬럼 값이 똑같이 변경되어야 
          제대로 다른 태스크(Task) B 또한 정상적으로 돌아갈텐데 실제로는 이와 같이 하면 특정 컬럼 값이 똑같이 변경되지 않는다.
          하여 서로 다른 태스크(Task)(또는 서로 다른 컨테이너) A, B 끼리 
          각각 DB(postgres 등등...)를 AWS ECS(Amazon Elastic Container Service)로 띄우지 않고(올리지 않고)
          DB(postgres 등등...) 파일을 공유하고 싶으면 
          1) AWS EFS(Elastic File System)에 DB(postgres 등등...)을 띄워야 한다.(올려야 한다.)
          2) 아니면 DB(postgres 등등...)는 AWS RDS에 따로 밖에다 만들어두고 사용해야 한다.

그래서 AWS ECS(Amazon Elastic Container Service)에 웹서버, nginx 만든걸 띄워볼 것(올려볼 것)인데 그 전에 셋팅할게 있다.

1. 이미지들을 리포지토리에 미리 올려두자.
AWS ECR(Amazon Elastic Container Service)이라는곳도 있는데 docker hub 공짜니까 거기 퍼블릭 리포지토리에 올려두자.
어딘가에 올려둬야 쉽게 가져다가 배포할 수 있으니까요.

2. 태스크(Task) 안에 있는 컨테이너들은 서로 http://localhost:포트로 통신해야한다.
그래서 nginx가 웹서버 컨테이너를 부를 때 localhost:8080이런 식으로 부르도록 수정해보자.

(예) (어쩌구.conf)

server {
        listen 80;
        location / {
            proxy_pass http://localhost:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
}

웹서버는 8080번 포트에 띄워놨기 때문에
웹서버 부르려면 http://localhost:8080 이런 식으로 주소를 입력해야한다.

그래서 참고로 같은 태스크(Task) 안에 있는 컨테이너끼리 포트 번호가 겹치고 그러면 안된다.
나중에 다른 서비스(Service)에 있는 태스크(Task)를 부르려면 localhost:8080 자리에 다른 서비스(Service) 이름을 적으면 된다.

아무튼 nginx, 웹서버 이미지들 빌드하고 docker hub에 올려놓자.
* Docker hub 사이트에 방문해봅시다. (hub.docker.com)
* nginx docker hub에 올려놓는 방법(docker push).
참고 URL - https://chatgpt.com/c/68647d8f-11e4-8010-9acf-4405cd30deb3
주의사항 - Docker desktop 터미널창에서 명령어 "docker push minjaejeon0827/nginx:1" 실행시 
          아래와 같은 오류 메시지 발생하는 경우 명령어 "docker tag nginx:latest minjaejeon0827/nginx:1"를 먼저 실행하여 이미지 "nginx"의 태그(tag)를 "1"로 붙여야함.
          Docker desktop 터미널창 명령어 실행 순서 
          1) docker images - 먼저 로컬에 있는 nginx 이미지 확인
          2) docker tag nginx:latest minjaejeon0827/nginx:1 - 해당 이미지에 원하는 태그(tag) "1" 붙이기 
             (또는 docker tag nginx:latest minjaejeon0827/mynginx:1)
          3) docker push minjaejeon0827/nginx:1 - nginx docker hub에 올려놓기(public 리포지토리명 "minjaejeon0827/nginx") 
             (또는 docker push minjaejeon0827/mynginx:1 - public 리포지토리명 "minjaejeon0827/mynginx")

오류 메시지 
- "PS C:\Users\bhjeon> docker push minjaejeon0827/nginx:1
>> 
The push refers to repository [docker.io/minjaejeon0827/nginx]
An image does not exist locally with the tag: minjaejeon0827/nginx"

이 오류 메시지는 다음과 같은 의미이다:
❗ "An image does not exist locally with the tag: minjaejeon0827/nginx"
→ 즉, docker push 하려는 minjaejeon0827/nginx:1이라는 로컬 이미지가 존재하지 않는다는 뜻이다.

15강 - Orchestration 2. 태스크 정의, health check

▲ AWS 사이트 방문하면 우측 상단에 지역을 선택할 수 있는데
서울에서 서비스할거면 서울(ap-northeast-2) 고르고 검색창에서 ECS(Amazon Elastic Container Service) 검색해서 들어가자.

* EC2 vs Fargate
컨테이너 띄우려면 1. 클러스터(Cluster) 만들고 2. 서비스(Service) 만들고 3. 태스크(Task) 만들면 된다.
그래서 ECS(Amazon Elastic Container Service) 검색해서 들어가서 클러스터(Cluster) 생성부터 눌러보자.
클러스터(Cluster)는 프로젝트 하나라고 생각하면 되는데
근데 정확하는 내가 컴퓨터를 몇대나 미리 점유할건지 정하려고 클러스터(Cluster)를 만드는 것이다.

▲ 클러스터(Cluster) 하나 생성하려면 인프라부터 고르라고 되어있을 것이다.
EC2는 컴퓨터를 직접 빌릴 수 있는 상품이고 Fargate는 서버리스형태로 CPU, RAM을 필요할 때만 꺼내쓰는 방식이다.

▲ 그래서 EC2를 고르면 컴퓨터를 원하는 용량과 갯수로 빌릴 수 있다. 
AWS 처음 카드등록하면 t2.micro 또는 t3.micro 라는 똥컴하나 1년무료 이용권주는데 그걸 쓸 수도 있다.

참고로 이미지 만들 때 사용했던 CPU 아키텍쳐와 같은 컴퓨터를 빌려야 잘돌아간다.
대부분 AMD64 (일명 x86-64) 라는 CPU 아키텍처로 만들었을거라 그게 표기된 컴퓨터를 빌려야한다.
드물게 ARM64로 이미지를 빌드했으면 그게 표기된 컴퓨터를 빌려서 쓰자.

근데 Fargate라는 옵션을 쓰면 컴퓨터를 미리 점유하는게 아니라 서버리스형태로
여러분이 필요할 때 마다 컴퓨터자원을 마법처럼 끌어다가 쓸 수 있다.

EC2보다 요금이 20% 정도 더 비싸지만 편하니까 이걸 쓰자.
서비스(Service) 만들어보고 바로 지우면 요금도 몇백원 나올까말까 하니까 
그냥 까까 사먹을 돈으로 이런거 경험해보도록 하자.

아무튼 다른건 딱히 건드릴 필요 없고 클러스터(Cluster) 이름 아무거나 잘 지어서 생성이나 해보자.

주의사항 - 아래와 같은 오류 메시지 발생하여 테스트용 클러스터(testCluster) 실패시 아마존 웹서비스(AWS) IAM > 역할(역할 이름 - EC2ContainerServiceRole) 새로 생성하기 
          (역할에 매핑되는 정책 - AmazonEC2ContainerServiceRole)
          만약 테스트용 클러스터(testCluster) 계속 실패시 아마존 웹서비스(AWS) CloudFormation -> 스택 들어가서 오류가 발생한 스택 삭제하기 
오류 메시지 - 클러스터 testCluster 생성 중 오류가 발생했습니다.
            Resource handler returned message: "Invalid request provided: CreateCluster Invalid Request: Unable to assume the service linked role. 
            Please verify that the ECS service linked role exists. 
            (Service: AmazonECS; Status Code: 400; Error Code: InvalidParameterException; Request ID: 7db52101-4978-47e2-af40-85296382b043; Proxy: null)" 
            (RequestToken: e7952b4b-b061-3338-c3c6-e5c4e47d603f, HandlerErrorCode: InvalidRequest)
참고 URL - https://velog.io/@khyup0629/AWS-EKS-Cluster-%EC%97%AD%ED%95%A0-%EC%83%9D%EC%84%B1
참고 2 URL - https://chatgpt.com/c/68671910-e5d0-8010-b647-a736dc957a5c

* 태스크(Task) 정의 (task definition)
클러스터(Cluster) → 서비스(Service) → 태스크(Task)를 띄운다고 했는데
참고로 서비스(Service) 없이 클러스터(Cluster) → 태스크(Task)만 띄울 수도 있다.
1회성 작업같은걸 하는 이미지 띄울 때는 그래도 상관없음

근데 지속적으로 안정적으로 실행되어야하는 이미지는 서비스(Service) 안에 넣는게 좋다. 
왜냐면 서비스(Service) 안에 태스크(Task)를 넣으면
하나가 망가졌을 때 자동으로 새로운 태스크(Task)로 갈아치우는 기능,
중단없이 태스크(Task)를 업데이트할 수 있는 기능 같은게 있어서 그렇다.

태스크(Task) 정의는 태스크(Task)를 어떻게 띄울지 정의하는 파일이다.
"무슨 이미지들을 어떤 포트에 어떤 환경변수를 넣어서 띄울지" 쭉 작성하는 파일일 뿐이고
실은 docker compose 파일이랑 똑같다.
하지만 ECS(Amazon Elastic Container Service) 문법에 따라 .json 형식으로 작성해야할 뿐인데
.json 그딴거 모르겠으면 웹페이지에서 클릭질로 작성할 수 있게 되어있다.

▲ 태스크(Task) 정의 만들기 누르면 일단 인프라를 또 고르게 하자.
클러스터(Cluster)에서 예약해놨던 컴퓨터를 태스크(Task) 1개가 얼마나 점유할 것인지 정하는 부분이다.

그래서 이 태스크(Task)가 얼마의 CPU, 메모리가 필요한지 정하면 된다.
사진에선 CPU 1개, 메모리 2GB를 골라봤는데
이 태스크(Task) 안에 컨테이너가 여러개 있을 예정이면 CPU 1개, 메모리 2GB를 컨테이너간 나눠써야한다.

나중에 변경 가능하니까 대충하자.

주의사항 - 태스크(Task) 역할(ecsTaskExecutionRole) 생성하고 태스크(Task) 정의 만들기 시작하기 
참고 URL - https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/task_execution_IAM_role.html

Elastic Container Service에 대한 서비스 역할을 생성하는 방법(IAM 콘솔)
1. AWS Management Console에 로그인하여 https://console.aws.amazon.com/iam/ 에서 IAM 콘솔을 엽니다.
2. IAM 콘솔의 탐색 창에서 역할을 선택하고 역할 생성을 선택합니다.
3. 신뢰할 수 있는 엔터티 유형에 AWS 서비스를 선택합니다.
4. 서비스 또는 사용 사례의 경우 Elastic Container Service를 선택하고 Elastic Container Service 작업 사용 사례를 선택합니다.
5. 다음을 선택합니다.
6. 권한 추가 섹션에서 AmazonECSTaskExecutionRolePolicy를 검색하고 정책을 선택합니다.
7. 다음을 선택합니다.
8. 역할 이름에 ecsTaskExecutionRole을 입력합니다.
9. 역할을 검토한 다음 역할 생성을 선택합니다.

* 태스크(Task) 정의 안에 컨테이너 작성하기

▲ 태스크(Task) 정의 안엔 컨테이너를 어떻게 띄울지 작성할 수 있다.
우리는 nginx, 웹서버(nodeserver)를 띄울 것이기 때문에 2개 띄운다고 작성하면 된다.

일단 첫 컨테이너엔 웹서버(nodeserver) 컨테이너 띄운다고 이름(webserver)이랑 이미지 다운받을 수 있는 경로(이미지 URI)를 작성해봤다.
docker hub에 올려놨을 경우엔 docker.io/내아이디/리포지토리명:태그명 입력하면 된다.
(예) 이름 - webserver / 이미지 URI - docker.io/minjaejeon0827/myserver:latest 또는 docker.io/minjaejeon0827/myserver:1

사진처럼 포트도 설정할 수 있다.
근데 웹서버(nodeserver)는 nginx에서 접속할거라 포트를 연결할 필요는 없어보여서 지워도 될듯 하군요.

▲ 컨테이너마다 CPU, 메모리를 얼마나 할당할 것인지 정할 수 있다.
아까 저는 태스크(Task)에 CPU 1개, 메모리 2GB를 할당했는데
그 안에서 nginx, 웹서버(nodeserver)는 각각 얼마의 CPU, 메모리를 점유할지 맘대로 결정하면 된다.

메모리 제한도 설정할 수 있는데 soft limit은 메모리를 얼마나 미리 최소로 선점할지,
hard limit은 최댓값이다.

hard limit 설정하면 그걸 도달하는 경우 컨테이너가 강제종료 될텐데 아마 비워도 상관없음
nodejs 서버의 경우에는 최소 메모리 1GB는 주는게 좋다.

나중에 테스트해보면서 늘리거나 줄이거나 해도 된다.
이외에 환경변수, 로깅옵션 이런건 필요할 때 사용하자.

처음엔 에러났을 때 상세히 볼게 필요하기 때문에 로깅하라고 해놓는게 좋다.

* 상태확인 (healthcheck)

새로운 개념 하나만 배우고 가자.
내 nodejs 웹서버(nodeserver) 컨테이너가 잘 떠있는지 확인하고 싶으면 어떻게 하죠?
웹브라우저 켜서 들어가보면 되겠지만 포트 연결을 안해놨으면 그건 좀 어려울 수 있다.

가장 쉬운 방법은 nodejs 웹서버(nodeserver) 컨테이너에 접속해서 localhost:8080으로 들어가보면 된다.
터미널로 들어갈 수 있으니까 아마 curl localhost:8080 이런거 쳐보면 알 수 있겠군요.

근데 그 작업을 자동화해줄 수도 있다.
자동으로 니가 알아서 5초마다 curl localhost:8080 쳐보라고 할 수 있는데 그걸 멋있는 말로 healthcheck라고 한다. 

▲ 그래서 여기에 터미널 명령어를 적으면 그걸 얘가 컨테이너 안에서 자동으로 X초마다 실행해준다.
일종의 컨테이너 모니터링 방법이라고 생각하면 된다.

CMD-SHELL, curl -f http://localhost:8080 || exit 1
그냥 기본적으로 이거 채우고 시작하면 되는데
CMD-SHELL 이건 bash같은 기본적인 쉘을 쓰라는 것이고
그 오른쪽에 명령어 입력하면 되는데 대부분 curl 이런거 쓰면 된다.

그리고 curl 요청이 실패하면 exit 1 하라고 코드짜면 되는데 exit 1 이런게 헬스체크를 실패했다는 암구호같은 거라 써주면 된다.
그리고 밑에 몇초마다 할건지 이런건 쭉 읽어보면서 알아서 적으면 된다.

* curl 있나 확인하는 것도 좋음

근데 가끔 curl 이런 기본 프로그램이 설치 안되어있는 이미지나 OS가 있다.
예를 들어 node:20-slim 이런 것도 이미지에 curl이 설치안되어있을 수 있는데
그래서 이거 실행하기 전에 직접 컨테이너에 들어가서 curl 커맨드 잘 되나 확인해보는것도 좋다.

curl이 없으면
- wget 그런거 찾아서 써도 되고
- 이미지에 직접 curl 설치하라고 Dockerfile에 기재해도 되고
- bash 정도는 있으면 bash 내장 기능중에 특정 페이지로 요청해주는 그런 비밀기능이 있어서 그거 써도 된다.

timeout 10s bash -c ': > /dev/tcp/localhost/8080' || exit 1

▲ bash에서 /dev/tcp/localhost/8080 이런식으로 적으면 신기하게도 localhost:8080에 TCP 요청을 날려준다.
TCP요청은 그냥 접속해본다는 뜻이고
이미지에 bash가 있으면 이걸 써서 헬스체크 해도 된다.

근데 그냥 /dev/tcp/localhost/8080 이렇게 입력만 하면 그 디렉터리 열라는 뜻이 될 수 있어서
그걸 방지하려고 : > 이런 이상한 기호도 쓰면 된다.
: 이건 텅빈 값이라는 뜻이고 
> 이건 왼쪽 값을 오른쪽에 작성하라는 뜻이다.
그래서 텅빈 값을 그 경로에 넣으라고 의미없는 명령어를 추가해준 것인데 그래야 잘동작한다.

* nginx 컨테이너도 띄우기

▲ 웹서버(nodeserver) 컨테이너 말고 nginx 컨테이너도 띄워야하니까 컨테이너 하나 추가해서 잘 입력해보자.
컨테이너 이름, URI, 포트는 80:80, CPU와 메모리 적절히, healthcheck는 기본명령어
이런거 설정하는 것 말고는 딱히 건드릴게 없으니 알아서 남자답게 채워보자.

healthcheck 기본명령어: CMD-SHELL, curl -f http://localhost:80 || exit 1

일단 두번째 컨테이너엔 nginx 컨테이너 띄운다고 이름(nginx1)이랑 이미지 다운받을 수 있는 경로(이미지 URI)를 작성해봤다.
docker hub에 올려놨을 경우엔 docker.io/내아이디/리포지토리명:태그명 입력하면 된다.
(예) 이름 - nginx1 / 이미지 URI - docker.io/minjaejeon0827/mynginx:latest 또는 docker.io/minjaejeon0827/mynginx:1

아무튼 다 됐으면 태스크(Task) 정의 생성 눌러보면 된다.
이제 클러스터(Cluster) 들어가서 서비스(Service) 생성 누르고 태스크(Task) 골라서 띄우면 되는데 그건 다음에 해보도록 하자.